{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stergios-Konstantinidis/DMML2022_Nestle/blob/main/DMML2022_Nestle_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZKqCFFbNZ04"
      },
      "source": [
        "# Data Mining and Machine Learning - Project\n",
        "\n",
        "## Detecting Difficulty Level of French Texts\n",
        "\n",
        "### Step by step guidelines\n",
        "\n",
        "The following are a set of step by step guidelines to help you get started with your project for the Data Mining and Machine Learning class. \n",
        "To test what you learned in the class, we will hold a competition. You will create a classifier that predicts how the level of some text in French (A1,..., C2). The team with the highest rank will get some goodies in the last class (some souvenirs from tech companies: Amazon, LinkedIn, etc).\n",
        "\n",
        "**2 people per team**\n",
        "\n",
        "Choose a team here:\n",
        "https://moodle.unil.ch/mod/choicegroup/view.php?id=1305831\n",
        "\n",
        "\n",
        "#### 1. ðŸ“‚ Create a public GitHub repository for your team using this naming convention `DMML2022_[your_team_name]` with the following structure:\n",
        "- data (folder) \n",
        "- code (folder) \n",
        "- documentation (folder)\n",
        "- a readme file (.md): *mention team name, participants, brief description of the project, approach, summary of results table and link to the explainatory video (see below).*\n",
        "\n",
        "All team members should contribute to the GitHub repository.\n",
        "\n",
        "#### 2. ðŸ‡° Join the competititon on Kaggle using the invitation link we sent on Slack.\n",
        "\n",
        "Under the Team tab, save your team name (`UNIL_your_team_name`) and make sure your team members join in as well. You can merge your user account with your teammates in order to create a team.\n",
        "\n",
        "#### 3. ðŸ““ Read the data into your colab notebook. There should be one code notebook per team, but all team members can participate and contribute code. \n",
        "\n",
        "You can use either direct the Kaggle API and your Kaggle credentials (as explained below and **entirely optional**), or dowload the data form Kaggle and upload it onto your team's GitHub repository under the data subfolder.\n",
        "\n",
        "#### 4. ðŸ’Ž Train your models and upload the code under your team's GitHub repo. Set the `random_state=0`.\n",
        "- baseline\n",
        "- logistic regression with TFidf vectoriser (simple, no data cleaning)\n",
        "- KNN & hyperparameter optimisation (simple, no data cleaning)\n",
        "- Decision Tree classifier & hyperparameter optimisation (simple, no data cleaning)\n",
        "- Random Forests classifier (simple, no data cleaning)\n",
        "- another technique or combination of techniques of your choice\n",
        "\n",
        "BE CREATIVE! You can use whatever method you want, in order to climb the leaderboard. The only rule is that it must be your own work. Given that, you can use all the online resources you want. \n",
        "\n",
        "#### 5. ðŸŽ¥ Create a YouTube video (10-15 minutes) of your solution and embed it in your notebook. Explain the algorithms used and the evaluation of your solutions. *Select* projects will also be presented live by the group during the last class.\n",
        "\n",
        "\n",
        "### Submission details (one per team)\n",
        "\n",
        "1. Download a ZIPped file of your team's repository and submit it in Moodle here. IMPORTANT: in the comment of the submission, insert a link to the repository on Github.\n",
        "https://moodle.unil.ch/mod/assign/view.php?id=1305833\n",
        "\n",
        "\n",
        "\n",
        "### Grading (one per team)\n",
        "- 20% Kaggle Rank\n",
        "- 50% code quality (using classes, splitting into proper files, documentation, etc)\n",
        "- 15% github quality (include link to video, table with progress over time, organization of code, images, etc)\n",
        "- 15% video quality (good sound, good slides, interesting presentation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-14CAdOoinM"
      },
      "source": [
        "## Some further details for points 3 and 4 above.\n",
        "\n",
        "### 3. Read data into your notebook with the Kaggle API (optional but useful). \n",
        "\n",
        "You can also download the data from Kaggle and put it in your team's repo the data folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ_hnJzSNO2g",
        "outputId": "8a748f49-8206-40d9-b0be-05333b3c1f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# reading in the data via the Kaggle API\n",
        "\n",
        "# mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJPTz3D7TeQv"
      },
      "outputs": [],
      "source": [
        "# install Kaggle\n",
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKG1TCddRYTB"
      },
      "source": [
        "### IMPORTANT\n",
        "Log into your Kaggle account, go to Account > API > Create new API token. You will obtain a kaggle.json file. Save it in your Google Drive (not in a folder, in your general drive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JgzLj451YDfV"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KrsZLalrSI3u"
      },
      "outputs": [],
      "source": [
        "#read in your Kaggle credentials from Google Drive\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-ETUrrhgdnfU"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BDI60LXKTPzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b5aefd-5842-44fc-f89b-b5f76f300d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading detecting-french-texts-difficulty-level-2022.zip to /content\n",
            "100% 303k/303k [00:00<00:00, 462kB/s]\n",
            "100% 303k/303k [00:00<00:00, 461kB/s]\n",
            "Archive:  detecting-french-texts-difficulty-level-2022.zip\n",
            "  inflating: data/sample_submission.csv  \n",
            "  inflating: data/training_data.csv  \n",
            "  inflating: data/unlabelled_test_data.csv  \n"
          ]
        }
      ],
      "source": [
        "# download the dataset from the competition page\n",
        "\n",
        "try:\n",
        "  df = pd.read_csv('/content/data/training_data.csv')\n",
        "except:\n",
        "  !kaggle competitions download -c detecting-french-texts-difficulty-level-2022\n",
        "  !unzip \"detecting-french-texts-difficulty-level-2022.zip\" -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "daqvj7feTx60"
      },
      "outputs": [],
      "source": [
        "# read in your training data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn \n",
        "#import sklearn.model_selection\n",
        "\n",
        "df = pd.read_csv('/content/data/training_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxRSnk5bhTp8"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kpfbtndj0jL"
      },
      "source": [
        "Have a look at the data on which to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7G75Q1gRj49l",
        "outputId": "cbf12f8f-45bb-4613-d3ea-2712b799b542"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence\n",
              "0   0  Nous dÃ»mes nous excuser des propos que nous eÃ»...\n",
              "1   1  Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
              "2   2  Et, paradoxalement, boire froid n'est pas la b...\n",
              "3   3  Ce n'est pas Ã©tonnant, car c'est une saison my...\n",
              "4   4  Le corps de Golo lui-mÃªme, d'une essence aussi..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47b30aec-aecb-469f-92a3-348cd6247392\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous dÃ»mes nous excuser des propos que nous eÃ»...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ce n'est pas Ã©tonnant, car c'est une saison my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Le corps de Golo lui-mÃªme, d'une essence aussi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47b30aec-aecb-469f-92a3-348cd6247392')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47b30aec-aecb-469f-92a3-348cd6247392 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47b30aec-aecb-469f-92a3-348cd6247392');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_pred = pd.read_csv('/content/data/unlabelled_test_data.csv')\n",
        "df_pred.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a37hWJ_ckBlk"
      },
      "source": [
        "And this is the format for your submissions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gk9H2dLHkFBa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "09aba53b-78ef-4e87-9f2d-13c3558b8546"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id difficulty\n",
              "0   0         A1\n",
              "1   1         A1\n",
              "2   2         A1\n",
              "3   3         A1\n",
              "4   4         A1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82bcd48c-8b8f-4602-bde9-6a175af2794f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82bcd48c-8b8f-4602-bde9-6a175af2794f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82bcd48c-8b8f-4602-bde9-6a175af2794f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82bcd48c-8b8f-4602-bde9-6a175af2794f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_example_submission = pd.read_csv('/content/data/sample_submission.csv')\n",
        "df_example_submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports\n"
      ],
      "metadata": {
        "id": "28xwBiprNAFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTS\n",
        "#pip install numpy \n",
        "#pip install scipy\n",
        "import spacy\n",
        "\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
        "import spacy.cli\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
        "import numpy as np\n",
        "from sklearn import linear_model, decomposition, datasets\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "PPRACtsDM_mu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfTgL1erjqQ6"
      },
      "source": [
        "### 4. Train your models\n",
        "\n",
        "Set your X and y variables. \n",
        "Set the `random_state=0`\n",
        "Split the data into a train and test set using the following parameters `train_test_split(X, y, test_size=0.2, random_state=0)`.\n",
        "\n",
        "#### 4.1.Baseline\n",
        "What is the baseline for this classification problem?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Baseline \n",
        "X= df['sentence']\n",
        "y= df['difficulty']\n",
        "y.value_counts()/len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-DkuNizqF3T",
        "outputId": "249e1ed5-0c69-43b9-9ad4-6e32d13840d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A1    0.169375\n",
              "C2    0.168125\n",
              "C1    0.166250\n",
              "B1    0.165625\n",
              "A2    0.165625\n",
              "B2    0.165000\n",
              "Name: difficulty, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlvbPYa0k78l"
      },
      "source": [
        "#### 4.2. Logistic Regression (without data cleaning)\n",
        "\n",
        "Train a simple logistic regression model using a Tfidf vectoriser."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data set\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "M0zWbByFLrq_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We vectorize our data set because it wouldnt pass the logistic regression, for this we use the Tfidfvectorizer:"
      ],
      "metadata": {
        "id": "V3v4i1msL2tV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eEe3-QNlow4H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "744dac2b-ea93-4eaa-9c3f-fb70eea4e61e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      000  02h00  03h00   10  100  1000  10000  105   11  110  ...  Ã©vÃ©nement  \\\n",
              "0     0.0    0.0    0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  ...        0.0   \n",
              "1     0.0    0.0    0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  ...        0.0   \n",
              "2     0.0    0.0    0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  ...        0.0   \n",
              "3     0.0    0.0    0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  ...        0.0   \n",
              "4     0.0    0.0    0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  ...        0.0   \n",
              "...   ...    ...    ...  ...  ...   ...    ...  ...  ...  ...  ...        ...   \n",
              "4795  0.0    0.0    0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  ...        0.0   \n",
              "4796  0.0    0.0    0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  ...        0.0   \n",
              "4797  0.0    0.0    0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  ...        0.0   \n",
              "4798  0.0    0.0    0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  ...        0.0   \n",
              "4799  0.0    0.0    0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  ...        0.0   \n",
              "\n",
              "      Ã©vÃ©nements  Ãªtes  Ãªtre  Ãªtres  Ãªut  Ã®le  Ã®les  Ã´ta  Ã´ter  \n",
              "0       0.000000   0.0   0.0    0.0  0.0  0.0   0.0  0.0   0.0  \n",
              "1       0.000000   0.0   0.0    0.0  0.0  0.0   0.0  0.0   0.0  \n",
              "2       0.000000   0.0   0.0    0.0  0.0  0.0   0.0  0.0   0.0  \n",
              "3       0.000000   0.0   0.0    0.0  0.0  0.0   0.0  0.0   0.0  \n",
              "4       0.000000   0.0   0.0    0.0  0.0  0.0   0.0  0.0   0.0  \n",
              "...          ...   ...   ...    ...  ...  ...   ...  ...   ...  \n",
              "4795    0.000000   0.0   0.0    0.0  0.0  0.0   0.0  0.0   0.0  \n",
              "4796    0.000000   0.0   0.0    0.0  0.0  0.0   0.0  0.0   0.0  \n",
              "4797    0.000000   0.0   0.0    0.0  0.0  0.0   0.0  0.0   0.0  \n",
              "4798    0.200821   0.0   0.0    0.0  0.0  0.0   0.0  0.0   0.0  \n",
              "4799    0.000000   0.0   0.0    0.0  0.0  0.0   0.0  0.0   0.0  \n",
              "\n",
              "[4800 rows x 14585 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53cf59fc-e979-4aef-bbd5-9a1fa17c4094\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>02h00</th>\n",
              "      <th>03h00</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>10000</th>\n",
              "      <th>105</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>...</th>\n",
              "      <th>Ã©vÃ©nement</th>\n",
              "      <th>Ã©vÃ©nements</th>\n",
              "      <th>Ãªtes</th>\n",
              "      <th>Ãªtre</th>\n",
              "      <th>Ãªtres</th>\n",
              "      <th>Ãªut</th>\n",
              "      <th>Ã®le</th>\n",
              "      <th>Ã®les</th>\n",
              "      <th>Ã´ta</th>\n",
              "      <th>Ã´ter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200821</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows Ã— 14585 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53cf59fc-e979-4aef-bbd5-9a1fa17c4094')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53cf59fc-e979-4aef-bbd5-9a1fa17c4094 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53cf59fc-e979-4aef-bbd5-9a1fa17c4094');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "texts = df['sentence']\n",
        "tfidf = TfidfVectorizer()\n",
        "features = tfidf.fit_transform(texts)\n",
        "pd.DataFrame(features.todense(),\n",
        "columns=tfidf.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that we vectorize also the Test and Training data set:"
      ],
      "metadata": {
        "id": "0N94cdU1NEfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)"
      ],
      "metadata": {
        "id": "NM3cwa6oNDlm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we do a logistic regression to classify the sentences, first we fit it on the training set: "
      ],
      "metadata": {
        "id": "n78wy0SMMuw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LogisticRegressionCV(solver='lbfgs', cv=2, max_iter=10, random_state = 50)\n",
        "LR.fit(X_train_text, y_train)\n",
        "y_pred = LR.predict(X_test_text)"
      ],
      "metadata": {
        "id": "r7-AKA73M5WD",
        "outputId": "aa1cc04d-a674-44e2-c8cb-05f8957565d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how our model performed:"
      ],
      "metadata": {
        "id": "UZxVCTEUNQO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "#Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "#Precision\n",
        "precision = precision_score(y_test, y_pred,average='micro')\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "#Recall\n",
        "recall = recall_score(y_test, y_pred,average='micro')\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "#F1\n",
        "f1 = f1_score(y_test, y_pred,average='macro')\n",
        "print('F1 score: %f' % f1)"
      ],
      "metadata": {
        "id": "wWhhTdAbsFgc",
        "outputId": "e7e00289-2b36-4ae6-dd80-b4aa0e3cdffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.463542\n",
            "Precision: 0.463542\n",
            "Recall: 0.463542\n",
            "F1 score: 0.458946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print sentence with the predicted language level\n",
        "\n",
        "#i=0\n",
        "#for text in X_test_text:\n",
        "  #print((X_test.reset_index())._get_value(i, \"sentence\", takeable=False) + \"  \" + LR.predict(text))\n",
        "  #i+=1\n",
        "  #df_pred = pd.read_csv('/content/data/unlabelled_test_data.csv')\n",
        "#df_pred_text = text_transformer.transform(df_pred[\"sentence\"])\n",
        "\n",
        "#df_pred['difficulty'] = list(map(lambda x : LR.predict(x)[0], df_pred_text))\n",
        "\n",
        "#df_pred = df_pred[[\"id\", \"difficulty\"]]\n",
        "#df_pred = df_pred.set_index('id')\n",
        "\n",
        "#df_pred.to_csv('LR_reg.csv')\n",
        "#df_pred.head()"
      ],
      "metadata": {
        "id": "1gQPHn8pV0pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D3_dp3apcmr"
      },
      "source": [
        "Have a look at the confusion matrix and identify a few examples of sentences that are not well classified."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(test, pred):\n",
        "  print(f'CONFUSION MATRIX:\\n{confusion_matrix(test, pred)}')\n",
        "evaluate(y_test, y_pred)\n",
        "\n",
        "sns.heatmap(pd.DataFrame(confusion_matrix(y_test, y_pred)), annot=True, cmap='Oranges', fmt='.4g');"
      ],
      "metadata": {
        "id": "_X606b3MKsCH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "560096f0-1dff-4e5e-c7ce-1ae014ac7c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[91 40 22  4  2  2]\n",
            " [49 59 34  7  4 11]\n",
            " [16 27 76 12  9 20]\n",
            " [10  2 18 55 25 34]\n",
            " [ 6  3 12 25 66 61]\n",
            " [ 6  6  8 17 23 98]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TTEiuXasNFg"
      },
      "source": [
        "Generate your first predictions on the `unlabelled_test_data.csv`. make sure your predictions match the format of the `unlabelled_test_data.csv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXG_yIG_pQ8t"
      },
      "source": [
        "#### 4.3. KNN (without data cleaning)\n",
        "\n",
        "Train a KNN classification model using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPRjD1rSqKKZ"
      },
      "outputs": [],
      "source": [
        "#Vectorize the dataset\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)\n",
        "\n",
        "#Split into Train and Test set\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, newY, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6rH2Hx0qtB2"
      },
      "source": [
        "Try to improve it by tuning the hyper parameters (`n_neighbors`,   `p`, `weights`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRy18Ce_qxPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d5757b6-117f-4630-8930-2cc81dae67d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 19 candidates, totalling 190 fits\n"
          ]
        }
      ],
      "source": [
        "#KNN with 6 neightbors accuracy 0.2073\n",
        "#KNN with 8 Neightbors accuracy 0.2073\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "#K in range from 1 to 8\n",
        "k_range = list(range(1, 20))\n",
        "param_grid = dict(n_neighbors=k_range)\n",
        "\n",
        "# defining parameter range\n",
        "knn_cv = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
        "  \n",
        "# fitting the model for grid search\n",
        "knn_cv.fit(X_train_text, y_train)\n",
        "\n",
        "y_pred_knn = knn_cv.predict(X_test_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN with minkowski and algorithm brute give us accuracy of: 0.1719\n",
        "KNeighborsClassifier(algorithm='brute', leaf_size=10, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
        "                     weights='uniform')\n",
        "knn.fit(X_train_text, y_train)\n",
        "\n",
        "y_pred_knn = knn.predict(X_test_text)"
      ],
      "metadata": {
        "id": "0PV9gUSySFY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(X_test_text)\n",
        "#Accuracy\n",
        "accuracy = accuracy_score(X_test_text, y_pred_knn)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "#Precision\n",
        "precision = precision_score(X_test_text, y_pred_knn)\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "#Recall\n",
        "recall = recall_score(X_test_text, y_pred_knn)\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "#F1\n",
        "f1 = f1_score(X_test_text, y_pred_knn)\n",
        "print('F1 score: %f' % f1)"
      ],
      "metadata": {
        "id": "AYR3ax_IHMIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFNH1WgNqc62"
      },
      "source": [
        "#### 4.4. Decision Tree Classifier (without data cleaning)\n",
        "\n",
        "Train a Decison Tree classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQHjvOp7q11L"
      },
      "source": [
        "Try to improve it by tuning the hyper parameters (`max_depth`, the depth of the decision tree)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Fzl5BUq8JN"
      },
      "outputs": [],
      "source": [
        "# first we tried depth 10, and accuracy of 0.1885\n",
        "# with deph=16 we have accuracy =0.1969\n",
        "# with deph=26 accuracy = 0.2042\n",
        "# with deph =40. accuracy=0.2021\n",
        "\n",
        "tree = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
        "                       max_depth=4000, \n",
        "                       random_state=50)\n",
        "tree.fit(X_train_text, y_train)\n",
        "y_pred_tree = tree.predict(X_test_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy, precision, f1\n",
        "\n",
        "y_pred = tree.predict(X_test_text)\n",
        "#Accuracy\n",
        "accuracy = accuracy_score(X_test_text, y_pred_knn)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "#Precision\n",
        "precision = precision_score(X_test_text, y_pred_knn)\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "#Recall\n",
        "recall = recall_score(X_test_text, y_pred_knn)\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "#F1\n",
        "f1 = f1_score(X_test_text, y_pred_knn)\n",
        "print('F1 score: %f' % f1)"
      ],
      "metadata": {
        "id": "0hGXj6RaaSAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M52Ys3hcq7ku"
      },
      "source": [
        "#### 4.5. Random Forest Classifier (without data cleaning)\n",
        "\n",
        "Try a Random Forest Classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "#df.oe_difficulty.value_counts()\n",
        "#newY = df['oe_difficulty']\n",
        "\n",
        "X= df['sentence']\n",
        "newY = df['difficulty']\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, newY, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "hMgVlrBb-wTh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We vectorize "
      ],
      "metadata": {
        "id": "c0Z57DjvKK7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['sentence']\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
        "features = tfidf.fit_transform(texts)\n",
        "pd.DataFrame(\n",
        "    features.todense(),\n",
        "    columns=tfidf.get_feature_names())"
      ],
      "metadata": {
        "id": "gw_8yLbsAvuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "#X_train_text = text_transformer.fit_transform(X_train)\n",
        "#X_test_text = text_transformer.transform(X_test)"
      ],
      "metadata": {
        "id": "6ptuGy7SBE_m"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "## Doesnt work because it's for continuous variable like housing price \n",
        "\n",
        "#rf = RandomForestRegressor(random_state = 42)\n",
        "#from pprint import pprint\n",
        "# Look at parameters used by our current forest\n",
        "#print('Parameters currently in use:\\n')\n",
        "#pprint(rf.get_params())"
      ],
      "metadata": {
        "id": "zbvloIiy7coB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using GridSearch to find the optimal parameters\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)"
      ],
      "metadata": {
        "id": "OcJh0i-y7krX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94b9b37-b4d1-4364-8fa9-abd30dc0d5cf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_clf = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 4, cv = 2, verbose=1, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_clf.fit(X_train_text, y_train)"
      ],
      "metadata": {
        "id": "8XZqDNxD7oFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9923d7b1-1361-4aab-9bd4-be43c2f87760"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=2, estimator=RandomForestClassifier(), n_iter=4,\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
              "                                                      70, 80, 90, 100, 110,\n",
              "                                                      None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [200, 400, 600, 800,\n",
              "                                                         1000, 1200, 1400, 1600,\n",
              "                                                         1800, 2000]},\n",
              "                   random_state=42, verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf_test = rf_clf.score(X_test_text, y_test)\n",
        "rf_clf_test\n",
        "0.41041666666666665"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug4FBMTZUlAU",
        "outputId": "38f3d56e-94e7-4693-d94b-52b6b6302303"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.41041666666666665"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We tried also to add some more parameters and fine tune the hyperparameter, it decreased our accuracy:"
      ],
      "metadata": {
        "id": "92E4CAnaL6Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Marche beaucoup moins bien\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_clf = RandomForestClassifier(criterion='gini',\n",
        "                                 n_estimators=5,\n",
        "                                 random_state=42,\n",
        "                                 n_jobs=20,\n",
        "                                max_depth=40,\n",
        "                                min_samples_split=5,\n",
        "                                max_features=30000,\n",
        "                                bootstrap = bool,\n",
        "                                oob_score= bool,\n",
        "                                warm_start= bool)\n",
        "# Fit the random search model\n",
        "rf_clf.fit(X_train_text, y_train)"
      ],
      "metadata": {
        "id": "xkEw2RuzUAi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac0ac8b-54d7-476b-d56c-c7b9cd5da3f3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:560: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=<class 'bool'>, max_depth=40,\n",
              "                       max_features=30000, min_samples_split=5, n_estimators=5,\n",
              "                       n_jobs=20, oob_score=<class 'bool'>, random_state=42,\n",
              "                       warm_start=<class 'bool'>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf_test = rf_clf.score(X_test_text, y_test)\n",
        "rf_clf_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ebo8JJYXFyf",
        "outputId": "6ca54cc5-3f40-48a5-ceb4-57f6afbd078f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.325"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf_test = rf_clf.score(X_test_text, y_test)\n",
        "rf_clf_test\n",
        "#0.325"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1jk8RyOBwsN",
        "outputId": "3201bb4a-57e4-4990-d425-438440e23340"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.325"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we apply the Random Forest Regressor, for this we need to label encode the Y:"
      ],
      "metadata": {
        "id": "XXY9ShnyN59c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot encoder ou label encoder \n",
        "\n",
        "df['oe_difficulty'] = ['0' if x == 'A1'\n",
        "                   else '1' if x =='A2'\n",
        "                   else '2' if x == 'B1'\n",
        "                   else '3' if x=='B2'\n",
        "                   else '4' if x== 'C1'\n",
        "                   else '5'\n",
        "                   for x in df.difficulty]\n",
        "\n",
        "#df.oe_difficulty.value_counts()\n",
        "#newY = df['oe_difficulty']\n",
        "\n",
        "X= df['sentence']\n",
        "newY = df['oe_difficulty']\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, newY, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "PqUWOEE-NGhN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestRegressor()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                          cv = 3, n_jobs = -1, verbose = 2)\n",
        "grid_search = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
        "grid_search.fit(X_train_text, y_train)"
      ],
      "metadata": {
        "id": "8ANhf-Eg7MlI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9b2ebc-0c80-4a2b-b535-7c92eb52cdb6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
              "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
              "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
              "                         'min_samples_split': [8, 10, 12],\n",
              "                         'n_estimators': [100, 200, 300, 1000]},\n",
              "             verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf_test = grid_search.score(X_test_text, y_test)\n",
        "rf_clf_test\n",
        "0.00014010622306859233"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ns_Kb4YO4lU",
        "outputId": "3b3d0208-9f9c-474b-821f-3a0ae1b6df62"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00014010622306859233"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-8_3MK1rpZr"
      },
      "source": [
        "#### 4.6. Any other technique, including data cleaning if necessary\n",
        "\n",
        "Try to improve accuracy by training a better model using the techniques seen in class, or combinations of them.\n",
        "\n",
        "As usual, show the accuracy, precision, recall and f1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first let's check if there are NA's\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gIJjicHh2B_",
        "outputId": "9fefab04-6e80-4ffa-ea54-0fd13acec6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id            0\n",
              "sentence      0\n",
              "difficulty    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le_diff = pd.Series(LabelEncoder().fit_transform(df[\"difficulty\"]), name=\"le_diff\")\n",
        "le_diff"
      ],
      "metadata": {
        "id": "jC8R5PMViQDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we one label encoded Y, because we thought that it will make the model easier to perform:"
      ],
      "metadata": {
        "id": "LlKm94F2Ne2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Label encoder \n",
        "\n",
        "X= df['sentence']\n",
        "df['oe_difficulty'] = ['0' if x == 'A1'\n",
        "                   else '1' if x =='A2'\n",
        "                   else '2' if x == 'B1'\n",
        "                   else '3' if x=='B2'\n",
        "                   else '4' if x== 'C1'\n",
        "                   else '5'\n",
        "                   for x in df.difficulty]\n",
        "\n",
        "df.oe_difficulty.value_counts()\n",
        "newY = df['oe_difficulty']\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, newY, test_size=0.1, random_state=0)\n",
        "\n",
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)"
      ],
      "metadata": {
        "id": "SMPE78ouNY3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try the logistic regression with the encoded Y:"
      ],
      "metadata": {
        "id": "cIdGMFHEN2pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LogisticRegressionCV(solver='lbfgs', cv=10, max_iter=100, random_state = 5)\n",
        "LR.fit(X_train_text, y_train)"
      ],
      "metadata": {
        "id": "TGLnPCrtOgJw",
        "outputId": "872f1465-f123-40a3-d14b-d299dc57d528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-a9a3cb6ac595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2075\u001b[0m             )\n\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   2078\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4320, 3840]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accur_test_LR = LR.score(X_test_text, y_test)\n",
        "accur_test_LR\n",
        "#0.4635416666666667"
      ],
      "metadata": {
        "id": "rtHy2MBlNvWN",
        "outputId": "2122cd03-6c3a-4770-8032-b2ae1d1d6763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following we tried another method, we droped most of the vectorized columns that contained integers and also hours. "
      ],
      "metadata": {
        "id": "RTyPTjWcZmHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NEW TEST\n",
        "#Vectorize\n",
        "#Drop columns with integer & hours\n",
        "\n",
        "X = pd.DataFrame(features.todense(), columns=tfidf.get_feature_names())\n",
        "y= df['difficulty']\n",
        "\n",
        "X.drop(X.iloc[:, 1:2000], inplace=True, axis=1)\n",
        "\n",
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=13000)\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=5)\n",
        "\n",
        "\n",
        "LR_cv = LogisticRegressionCV(solver='lbfgs', cv=10, max_iter=100, random_state = 0)\n",
        "\n",
        "LR_cv.fit(X_train, y_train)\n",
        "\n",
        "LR_accur_test = LR_cv.score(X_test, y_test)\n",
        "LR_accur_test"
      ],
      "metadata": {
        "id": "TJ0GcsL5ZlJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82FvnJycsBFf"
      },
      "source": [
        "#### 4.7. Show a summary of your results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following table there are the accuracy on the test set for each model & the variations of the model:"
      ],
      "metadata": {
        "id": "48sDwICbO-bd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.8. Log regression, SVM, Naive Bayes"
      ],
      "metadata": {
        "id": "vIDBOPu4-AHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "mEo6CyfeZz79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode Data\n",
        "#Split data set\n",
        "\n",
        "X= df['sentence']\n",
        "y= df['difficulty']\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "df['oe_difficulty'] = [0 if x == 'A1'\n",
        "                   else 2 if x =='A2'\n",
        "                   else 1 if x== 'B1'\n",
        "                   else 3 if x == 'B2'\n",
        "                   else 4 if x == 'C1'\n",
        "                   else 5\n",
        "                   for x in df.difficulty]\n",
        "df.drop(labels='difficulty', axis=1)\n",
        "\n",
        "#Encode column\n",
        "df.oe_difficulty.value_counts()\n",
        "newY = df['oe_difficulty']\n",
        "X= df['sentence']\n",
        "newY = df['oe_difficulty']\n",
        "\n",
        "#Encoded dataframe\n",
        "df_encoded= df.drop('difficulty', axis = 1)\n",
        "df_encoded\n",
        "\n",
        "#Vectorize\n",
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, newY, test_size=0.2, random_state=0)\n"
      ],
      "metadata": {
        "id": "6742PIoRdWpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pca = decomposition.PCA()\n",
        "#std_slc = StandardScaler()\n",
        "#logistic_Reg = linear_model.LogisticRegression()\n",
        "#pipe = Pipeline(steps=[('std_slc', std_slc),\n",
        "                           #('pca', pca),\n",
        "                           #('logistic_Reg', logistic_Reg)])\n",
        "\n",
        "#PCA\n",
        "#from sklearn.decomposition import PCA\n",
        "#pca = PCA(n_components=2)\n",
        "#pca.fit(X_train_text)\n",
        "#PCA(n_components=2)\n",
        "#print(pca.explained_variance_ratio_)\n",
        "#print(pca.singular_values_)"
      ],
      "metadata": {
        "id": "KiEWpL8BZp4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##NEW TEST\n",
        "\n",
        "#Vectorize\n",
        "texts = df['sentence']\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
        "features = tfidf.fit_transform(texts)\n",
        "pd.DataFrame(\n",
        "    features.todense(),\n",
        "    columns=tfidf.get_feature_names())\n",
        "\n",
        "#Transform\n",
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)\n",
        "\n",
        "#Split \n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCd2BNvXY4DG",
        "outputId": "72ef8fd2-8e08-4418-e93d-c61e9be0285c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR_cv = LogisticRegressionCV(solver='lbfgs', cv=10, max_iter=100, random_state = 0)\n",
        "LR_cv.fit(X_train_text, y_train)\n",
        "LR_accur_test = LR_cv.score(X_test_text, y_test)\n",
        "LR_accur_test"
      ],
      "metadata": {
        "id": "HSwzwt_L0pNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Label = [' Model', 'CV', 'Solver', 'Specifity', 'max_iter', 'Accuracy']\n",
        "LR_1 = ['Log_Reg', '2', 'lbfgs','Basic model', '10','0.4635']\n",
        "LR_2 = ['Log_Reg', '2', 'lbfgs','Label encoded Y','10', '0.4635']\n",
        "LR_3 = ['Log_Reg', '5', 'lbfgs','Label encoded Y','10', '0.4625'] #Cross validation sinks our accuracy\n",
        "LR_4 = ['Log_Reg', '5', 'lbfgs','Label encoded Y','100', '0.4677']\n",
        "LR_5 = ['Log_Reg', '5', 'newton-cg','Label encoded Y','100','0.46770'] #Multiclass probelms is newton-cg good, so we test it \n",
        "LR_5 = ['Log_Reg', '5', 'lbfgs','Label encoded Y','100','0.47083'] #\n",
        "LR_6 = ['Log_Reg', '10', 'lbfgs','Label encoded Y','500','0.55208'] #We augmented the cv and the number of iterations + vectorized sentences\n",
        "\n",
        "table_merge = pd.DataFrame([LR_1, LR_2, LR_3, LR_4, LR_5, LR_6],columns=Label)\n",
        "table_merge"
      ],
      "metadata": {
        "id": "5bqHj4JSaapA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine**"
      ],
      "metadata": {
        "id": "-H9-5cUNZnNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we vectorized before, we thought it could be a good idea to use the SVM Model. We increased the size of the training set from 80 to 90%, and the accuracy increased:"
      ],
      "metadata": {
        "id": "sSP-AeKPSlWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Support Vector Machine\n",
        "#Split \n",
        "from sklearn.model_selection import cross_val_score,KFold\n",
        "X= df['sentence']\n",
        "y= df['difficulty']\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.1, random_state=5)\n",
        "\n",
        "#Vectorize\n",
        "texts = df['sentence']\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
        "features = tfidf.fit_transform(texts)\n",
        "pd.DataFrame(\n",
        "    features.todense(),\n",
        "    columns=tfidf.get_feature_names())\n",
        "\n",
        "#Transform\n",
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)\n",
        "\n",
        "#Split here? \n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "              ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, warm_start= True ,random_state=77777, max_iter=200, class_weight = 'balanced',learning_rate='optimal',validation_fraction = 0.5,tol=None)),\n",
        "               ])\n",
        "#kf=KFold(n_splits=5)\n",
        "\n",
        "\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n"
      ],
      "metadata": {
        "id": "CGD5kWY_9vog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "kfFyaivoZsB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We tried also the naive bayes model:"
      ],
      "metadata": {
        "id": "qyCD7BFkTOCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive bayes test\n",
        "\n",
        "# Gaussian Naive Bayes Classification\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "\n",
        "#Encode column\n",
        "df.oe_difficulty.value_counts()\n",
        "newY = df['oe_difficulty']\n",
        "X= df['sentence']\n",
        "newY = df['oe_difficulty']\n",
        "\n",
        "#Encoded dataframe\n",
        "df_encoded= df.drop('difficulty', axis = 1)\n",
        "df_encoded\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, newY, test_size=0.1, random_state=5)\n",
        "\n",
        "#Vectorize\n",
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "\n",
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ] )\n",
        "\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n"
      ],
      "metadata": {
        "id": "Ac2FwiKxfc3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Label = [' Model', 'Batch', 'Epoch ', \"Specificity\",'accuracy']\n",
        "M1 = ['Naives Bayes', '', '', '','0.4823']\n",
        "M2 = ['Naives Bayes', '', '', 'Train Set= 0.9','0.5166']\n",
        "M3=['SVM', '', '', '', '0.4583']\n",
        "M4 =['SVM', '', '', 'Train set=0.9', '0.5270']\n",
        "M5 =['SVM', '', '', 'Train set=0.9 & Random state= 77777', '0.5229']\n",
        "table_merge_2 = pd.DataFrame([M1, M2, M3, M4, M5],columns=Label)\n",
        "table_merge_2"
      ],
      "metadata": {
        "id": "sku_tXTCZObK",
        "outputId": "be76d55e-588b-4156-d35a-c4c6a704c56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Model Batch Epoch                           Specificity accuracy\n",
              "0  Naives Bayes                                                     0.4823\n",
              "1  Naives Bayes                                    Train Set= 0.9   0.5166\n",
              "2           SVM                                                     0.4583\n",
              "3           SVM                                     Train set=0.9   0.5270\n",
              "4           SVM               Train set=0.9 & Random state= 77777   0.5229"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f234c418-89ad-4fcd-9319-9d57058b3e9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Batch</th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naives Bayes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.4823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naives Bayes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Train Set= 0.9</td>\n",
              "      <td>0.5166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVM</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.4583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVM</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Train set=0.9</td>\n",
              "      <td>0.5270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVM</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Train set=0.9 &amp; Random state= 77777</td>\n",
              "      <td>0.5229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f234c418-89ad-4fcd-9319-9d57058b3e9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f234c418-89ad-4fcd-9319-9d57058b3e9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f234c418-89ad-4fcd-9319-9d57058b3e9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.9. BERT\n",
        "\n"
      ],
      "metadata": {
        "id": "bH-5SfYm9T5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##NEW TEST\n",
        "\n",
        "#Vectorize\n",
        "texts = df['sentence']\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
        "features = tfidf.fit_transform(texts)\n",
        "pd.DataFrame(\n",
        "    features.todense(),\n",
        "    columns=tfidf.get_feature_names())\n",
        "\n",
        "#Transform\n",
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)\n",
        "\n",
        "#Split \n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "ISHYXWcE_0J3",
        "outputId": "eb225fa3-43e4-48ad-a4b5-5e4185649b1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###BERT MODEL\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "#Import bert model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Load the tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "oJQN5uoJXU4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_one = df.drop(['difficulty'], axis=1)\n",
        "df_one['oe_difficulty'].value_counts(normalize = True)\n",
        "df_one\n"
      ],
      "metadata": {
        "id": "S_FEeyS8keUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#lenghts of messages\n",
        "df_one['oe_difficulty'] = [0 if x == 'A1'\n",
        "                   else 2 if x =='A2'\n",
        "                   else 1 if x== 'B1'\n",
        "                   else 3 if x == 'B2'\n",
        "                   else 4 if x == 'C1'\n",
        "                   else 5\n",
        "                   for x in df.difficulty]\n",
        "df.drop(labels='difficulty', axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df_one['sentence'], df_one['oe_difficulty'],\n",
        "                                                                    random_state=2018,     \n",
        "                                                                    test_size=0.1, \n",
        "                                                                    stratify=df_one['oe_difficulty']) \n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.1, \n",
        "                                                                stratify=temp_labels)"
      ],
      "metadata": {
        "id": "FLiKL6NEkYGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)\n",
        "\n",
        "#The longest sequence message is 265\n",
        "max(seq_len)"
      ],
      "metadata": {
        "id": "zDH3a2vGlSMm",
        "outputId": "96ba47c6-92a7-446b-8061-cee0ca6f4729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "265"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVgElEQVR4nO3df7BcZX3H8feniWAllgSi2zTJ9EaNdiKpGldIR+tsxEIA66Uz6oSmEmg6d9oGxRJHg/6Bo8M02kEGRsrMVe4QOgxXirRkJBZjZMtkxgQI5UcCIhcIcu8EUgxGN1Qw8ds/9oks1/vz7N69P57Pa+bOPfuc55zzfHMyn3v22bO7igjMzCwPvzfZAzAzs/Zx6JuZZcShb2aWEYe+mVlGHPpmZhmZPdkDGMn8+fOjo6Oj0LZHjhzhpJNOau2AppgcaoQ86syhRnCd7bJnz54XIuJNQ62b0qHf0dHB/fffX2jbarVKpVJp7YCmmBxqhDzqzKFGcJ3tIumZ4dZ5esfMLCMOfTOzjIwa+pJ6JB2UtHdQ+6ck/VjSPklfa2i/XFKfpMclnd3Qvjq19Una1NoyzMxsLMYyp38j8A3gpuMNklYBncC7IuJlSW9O7cuANcA7gT8CfiDp7Wmz64C/APqB+yRtjYhHW1WImZmNbtTQj4h7JHUMav4HYHNEvJz6HEztnUBvan9aUh9welrXFxFPAUjqTX0d+mZmbVR0Tv/twJ9L2i3pvyW9L7UvBJ5t6Nef2oZrNzOzNip6y+Zs4BRgJfA+4FZJb2nFgCR1AV0ApVKJarVaaD+1Wq3wttNFDjVCHnXmUCO4zqmgaOj3A7dH/XOZ75X0G2A+MAAsbui3KLUxQvtrREQ30A1QLpej6L2uk32fbDvkUCPkUWcONYLrnAqKTu/8J7AKIL1QewLwArAVWCPpRElLgKXAvcB9wFJJSySdQP3F3q3NDt7MzMZn1Ct9SbcAFWC+pH7gCqAH6Em3cb4CrEtX/fsk3Ur9BdqjwIaIOJb2cwlwFzAL6ImIfRNQTyEdm+4cU7/9m8+b4JGYmU2ssdy9c8Ewq/5mmP5XAlcO0b4N2Dau0ZmZWUv5HblmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZWTU0JfUI+lg+j7cwes2SgpJ89NjSbpWUp+khyWtaOi7TtIT6Wdda8swM7OxGMuV/o3A6sGNkhYDZwE/bWg+B1iafrqA61PfU6h/ofoZwOnAFZLmNTNwMzMbv1FDPyLuAQ4Nsepq4HNANLR1AjdF3S5grqQFwNnA9og4FBEvAtsZ4g+JmZlNrNlFNpLUCQxExEOSGlctBJ5teNyf2oZrH2rfXdSfJVAqlahWq0WGSK1WG/O2G5cfHVO/omOZKOOpcTrLoc4cagTXORWMO/QlvQH4AvWpnZaLiG6gG6BcLkelUim0n2q1yli3vWjTnWPqt39tsbFMlPHUOJ3lUGcONYLrnAqK3L3zVmAJ8JCk/cAi4AFJfwgMAIsb+i5KbcO1m5lZG4079CPikYh4c0R0REQH9amaFRHxHLAVuDDdxbMSOBwRB4C7gLMkzUsv4J6V2szMrI3GcsvmLcCPgHdI6pe0foTu24CngD7gm8A/AkTEIeArwH3p58upzczM2mjUOf2IuGCU9R0NywFsGKZfD9AzzvGZmVkL+R25ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZGfWbsyT1AB8BDkbEaantX4C/BF4BngQujoifp3WXA+uBY8CnI+Ku1L4auAaYBXwrIja3vpzX6th050QfwsxsWhnLlf6NwOpBbduB0yLiT4GfAJcDSFoGrAHembb5V0mzJM0CrgPOAZYBF6S+ZmbWRqOGfkTcAxwa1Pb9iDiaHu4CFqXlTqA3Il6OiKepf0H66emnLyKeiohXgN7U18zM2mjU6Z0x+Fvg22l5IfU/Asf1pzaAZwe1nzHUziR1AV0ApVKJarVaaFC1Wo2Ny48V2nY4RccyUWq12pQb00TIoc4cagTXORU0FfqSvggcBW5uzXAgIrqBboByuRyVSqXQfqrVKlftPNKqYQGwf22xsUyUarVK0X+f6SSHOnOoEVznVFA49CVdRP0F3jMjIlLzALC4odui1MYI7WZm1iaFbtlMd+J8DvhoRLzUsGorsEbSiZKWAEuBe4H7gKWSlkg6gfqLvVubG7qZmY3XWG7ZvAWoAPMl9QNXUL9b50RguySAXRHx9xGxT9KtwKPUp302RMSxtJ9LgLuo37LZExH7JqAeMzMbwaihHxEXDNF8wwj9rwSuHKJ9G7BtXKMzM7OW8jtyzcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwyMmroS+qRdFDS3oa2UyRtl/RE+j0vtUvStZL6JD0saUXDNutS/yckrZuYcszMbCRjudK/EVg9qG0TsCMilgI70mOAc6h/GfpSoAu4Hup/JKh/t+4ZwOnAFcf/UJiZWfuMGvoRcQ9waFBzJ7AlLW8Bzm9ovynqdgFzJS0Azga2R8ShiHgR2M7v/iExM7MJNuoXow+jFBEH0vJzQCktLwSebejXn9qGa/8dkrqoP0ugVCpRrVYLDbBWq7Fx+bFC2w6n6FgmSq1Wm3Jjmgg51JlDjeA6p4Kiof9bERGSohWDSfvrBroByuVyVCqVQvupVqtctfNIq4YFwP61xcYyUarVKkX/faaTHOrMoUZwnVNB0bt3nk/TNqTfB1P7ALC4od+i1DZcu5mZtVHR0N8KHL8DZx1wR0P7hekunpXA4TQNdBdwlqR56QXcs1KbmZm10ajTO5JuASrAfEn91O/C2QzcKmk98AzwidR9G3Au0Ae8BFwMEBGHJH0FuC/1+3JEDH5x2MzMJtiooR8RFwyz6swh+gawYZj99AA94xqdmZm1lN+Ra2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGmgp9Sf8kaZ+kvZJukfR6SUsk7ZbUJ+nbkk5IfU9Mj/vS+o5WFGBmZmNXOPQlLQQ+DZQj4jRgFrAG+CpwdUS8DXgRWJ82WQ+8mNqvTv3MzKyNmp3emQ38vqTZwBuAA8CHgNvS+i3A+Wm5Mz0mrT9Tkpo8vpmZjYMiovjG0qXAlcD/Ad8HLgV2pat5JC0GvhcRp0naC6yOiP607kngjIh4YdA+u4AugFKp9N7e3t5CY6vVajx9+FixwoaxfOHJLd1fs2q1GnPmzJnsYUy4HOrMoUZwne2yatWqPRFRHmrd7KI7lTSP+tX7EuDnwL8Dq4vu77iI6Aa6AcrlclQqlUL7qVarXLXzSLPDeY39a4uNZaJUq1WK/vtMJznUmUON4Dqngmamdz4MPB0R/xsRvwZuB94PzE3TPQCLgIG0PAAsBkjrTwZ+1sTxzcxsnApf6QM/BVZKegP16Z0zgfuBu4GPAb3AOuCO1H9revyjtP6H0czc0iTo2HTnmPrt33zeBI/EzKyYwlf6EbGb+guyDwCPpH11A58HLpPUB5wK3JA2uQE4NbVfBmxqYtxmZlZAM1f6RMQVwBWDmp8CTh+i76+AjzdzPDMza47fkWtmlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlpGmQl/SXEm3SfqxpMck/ZmkUyRtl/RE+j0v9ZWkayX1SXpY0orWlGBmZmPV7JX+NcB/RcSfAO8CHqP+3bc7ImIpsINXvwv3HGBp+ukCrm/y2GZmNk6FQ1/SycAHSV98HhGvRMTPgU5gS+q2BTg/LXcCN0XdLmCupAWFR25mZuOmiCi2ofRuoBt4lPpV/h7gUmAgIuamPgJejIi5kr4LbI6InWndDuDzEXH/oP12UX8mQKlUem9vb2+h8dVqNZ4+fKzQts1avvDkthynVqsxZ86cthxrMuVQZw41gutsl1WrVu2JiPJQ62Y3sd/ZwArgUxGxW9I1vDqVA0BEhKRx/VWJiG7qf0wol8tRqVQKDa5arXLVziOFtm3W/rWVthynWq1S9N9nOsmhzhxqBNc5FTQzp98P9EfE7vT4Nup/BJ4/Pm2Tfh9M6weAxQ3bL0ptZmbWJoVDPyKeA56V9I7UdCb1qZ6twLrUtg64Iy1vBS5Md/GsBA5HxIGixzczs/FrZnoH4FPAzZJOAJ4CLqb+h+RWSeuBZ4BPpL7bgHOBPuCl1NfMzNqoqdCPiAeBoV4sOHOIvgFsaOZ4ZmbWHL8j18wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsI02HvqRZkv5H0nfT4yWSdkvqk/Tt9FWKSDoxPe5L6zuaPbaZmY1PK670LwUea3j8VeDqiHgb8CKwPrWvB15M7VenfmZm1kZNfUeupEXAecCVwGWSBHwI+OvUZQvwJeB6oDMtA9wGfEOS0nfnzigdm+4cU7/9m8+b4JGYmb2WmslcSbcB/wy8EfgscBGwK13NI2kx8L2IOE3SXmB1RPSndU8CZ0TEC4P22QV0AZRKpff29vYWGlutVuPpw8cKbdsuyxee3NT2tVqNOXPmtGg0U1cOdeZQI7jOdlm1atWeiCgPta7wlb6kjwAHI2KPpErR/QwWEd1AN0C5XI5Kpdiuq9UqV+080qphTYj9aytNbV+tVin67zOd5FBnDjWC65wKmpneeT/wUUnnAq8H/gC4BpgraXZEHAUWAQOp/wCwGOiXNBs4GfhZE8c3M7NxKvxCbkRcHhGLIqIDWAP8MCLWAncDH0vd1gF3pOWt6TFp/Q9n4ny+mdlUNhH36X+e+ou6fcCpwA2p/Qbg1NR+GbBpAo5tZmYjaOruneMiogpU0/JTwOlD9PkV8PFWHM/MzIrxO3LNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDJSOPQlLZZ0t6RHJe2TdGlqP0XSdklPpN/zUrskXSupT9LDkla0qggzMxubZq70jwIbI2IZsBLYIGkZ9e++3RERS4EdvPpduOcAS9NPF3B9E8c2M7MCCod+RByIiAfS8i+Bx4CFQCewJXXbApyfljuBm6JuFzBX0oLCIzczs3FryZy+pA7gPcBuoBQRB9Kq54BSWl4IPNuwWX9qMzOzNpnd7A4kzQG+A3wmIn4h6bfrIiIkxTj310V9+odSqUS1Wi00rlqtxsblxwpt2y5FazuuVqs1vY/pIIc6c6gRXOdU0FToS3od9cC/OSJuT83PS1oQEQfS9M3B1D4ALG7YfFFqe42I6Aa6AcrlclQqlUJjq1arXLXzSKFt22X/2kpT21erVYr++0wnOdSZQ43gOqeCZu7eEXAD8FhEfL1h1VZgXVpeB9zR0H5huotnJXC4YRrIzMzaoJkr/fcDnwQekfRgavsCsBm4VdJ64BngE2ndNuBcoA94Cbi4iWObmVkBhUM/InYCGmb1mUP0D2BD0eOZmVnz/I5cM7OMNH33jhXXsenOMfXbv/m8CR6JmeXCV/pmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcQfwzANDPdxDRuXH+WiQev8kQ1mNhJf6ZuZZcRX+jOMP8TNzEbiK30zs4w49M3MMuLQNzPLSNvn9CWtBq4BZgHfiojN7R6Dee7fLFdtvdKXNAu4DjgHWAZcIGlZO8dgZpazdl/pnw70RcRTAJJ6gU7g0TaPw8ZorM8IJtJQ70c4biKeiUxGzRuXH6XS9qNajhQR7TuY9DFgdUT8XXr8SeCMiLikoU8X0JUevgN4vODh5gMvNDHc6SCHGiGPOnOoEVxnu/xxRLxpqBVT7j79iOgGupvdj6T7I6LcgiFNWTnUCHnUmUON4DqngnbfvTMALG54vCi1mZlZG7Q79O8DlkpaIukEYA2wtc1jMDPLVlundyLiqKRLgLuo37LZExH7JuhwTU8RTQM51Ah51JlDjeA6J11bX8g1M7PJ5XfkmpllxKFvZpaRGRf6klZLelxSn6RNkz2eVpK0X9Ijkh6UdH9qO0XSdklPpN/zJnuc4yGpR9JBSXsb2oasSXXXpnP7sKQVkzfy8Rmmzi9JGkjn80FJ5zasuzzV+biksydn1OMjabGkuyU9KmmfpEtT+4w6nyPUOT3OZ0TMmB/qLw4/CbwFOAF4CFg22eNqYX37gfmD2r4GbErLm4CvTvY4x1nTB4EVwN7RagLOBb4HCFgJ7J7s8TdZ55eAzw7Rd1n6v3sisCT9n5412TWMocYFwIq0/EbgJ6mWGXU+R6hzWpzPmXal/9uPeYiIV4DjH/Mwk3UCW9LyFuD8SRzLuEXEPcChQc3D1dQJ3BR1u4C5kha0Z6TNGabO4XQCvRHxckQ8DfRR/789pUXEgYh4IC3/EngMWMgMO58j1DmcKXU+Z1roLwSebXjcz8gnY7oJ4PuS9qSPqwAoRcSBtPwcUJqcobXUcDXNxPN7SZra6GmYmpv2dUrqAN4D7GYGn89BdcI0OJ8zLfRnug9ExArqn1K6QdIHG1dG/bnkjLoHdybW1OB64K3Au4EDwFWTO5zWkDQH+A7wmYj4ReO6mXQ+h6hzWpzPmRb6M/pjHiJiIP0+CPwH9aeIzx9/Spx+H5y8EbbMcDXNqPMbEc9HxLGI+A3wTV59yj9t65T0OupBeHNE3J6aZ9z5HKrO6XI+Z1roz9iPeZB0kqQ3Hl8GzgL2Uq9vXeq2DrhjckbYUsPVtBW4MN31sRI43DBtMO0Mmr/+K+rnE+p1rpF0oqQlwFLg3naPb7wkCbgBeCwivt6wakadz+HqnDbnc7JfCW/1D/U7An5C/RXyL072eFpY11uo3wHwELDveG3AqcAO4AngB8Apkz3WcdZ1C/Wnwr+mPte5friaqN/lcV06t48A5ckef5N1/luq42HqwbCgof8XU52PA+dM9vjHWOMHqE/dPAw8mH7OnWnnc4Q6p8X59McwmJllZKZN75iZ2Qgc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5ll5P8BBLvEVg9s64sAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Tokenization \n",
        "#BERT uses Wordpiece tokenization: \n",
        "#The vocabulary is initialized with all the individual \n",
        "#characters in the language, and then the most frequent/likely combinations \n",
        "#of the existing words in the vocabulary are iteratively added.\n",
        "\n",
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = 200,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True)\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = 200,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True)\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 200,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True)\n",
        "\n",
        "print(test_text)\n"
      ],
      "metadata": {
        "id": "VHz-Bcevloc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## convert lists to tensors\n",
        "\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "ZJfqwDq5mi8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 1000\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "h585hUQWxllD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "r2B5Y6TBxsEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        \n",
        "        self.bert = bert \n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "        # relu activation function\n",
        "        self.relu =  nn.ReLU()\n",
        "\n",
        "        #Longest sequence = 265\n",
        "        # dense layer 1\n",
        "        self.fc1 = nn.Linear(768,265)\n",
        "      \n",
        "        #longest sequence 265 and 6 classes\n",
        "        # dense layer 2 (Output layer)\n",
        "        \n",
        "        self.fc2 = nn.Linear(265,6)\n",
        "\n",
        "        #softmax activation function\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "        \n",
        "        #pass the inputs to the model  \n",
        "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "        x = self.fc1(cls_hs)\n",
        "\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # output layer\n",
        "        x = self.fc2(x)\n",
        "      \n",
        "        # apply softmax activation\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "u_QzrWA4xvY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "cUVhhENvx0XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),lr = 1e-5) "
      ],
      "metadata": {
        "id": "7UYTGvLtx3Fc",
        "outputId": "bd59ffc1-fbfb-4cae-b4d5-9267c3309c1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################### RUN tututututuuu ########################################################\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes= np.unique(train_labels), y= train_labels)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "metadata": {
        "id": "Oqepu_WRx6BR",
        "outputId": "31b01d83-013e-4e1e-8ab6-a9647ec7bff6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [0.98360656 1.00699301 1.00558659 1.00981767 1.00278552 0.99173554]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# converting list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# push to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 3000"
      ],
      "metadata": {
        "id": "HiPZ8E2mCBEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## FINE TUNE\n",
        "\n",
        "# function to train the model\n",
        "def train():\n",
        "    \n",
        "    model.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "  \n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "        \n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "        \n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        " \n",
        "        sent_id, mask, labels = batch\n",
        "        print(\"ID\")\n",
        "        print(sent_id.type())\n",
        "        print(\"mask\")\n",
        "        print(mask.type())\n",
        "        # clear previously calculated gradients \n",
        "        model.zero_grad()        \n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "      # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "HljvGTgXCHGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "    \n",
        "    print(\"\\nEvaluating...\")\n",
        "  \n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "    \n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "        \n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            \n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            # model predictions\n",
        "            preds = model(sent_id, mask)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "\n",
        "            total_preds.append(preds)\n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "fO__50MdCK77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "id": "L6LkXbVoCW9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = 'drive/MyDrive/saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    df['sentence'][0:20].tolist(),\n",
        "    max_length = 200,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True)\n",
        "\n",
        "#print(tokens_test)\n",
        "torch.zeros([2,4], dtype=torch.int32)\n",
        "#print(torch.Tensor(tokens_test['attention_mask']))\n",
        "\n",
        "Input_id = torch.Tensor(tokens_test['input_ids'])\n",
        "\n",
        "Input_id = Input_id.type(torch.int64)\n",
        "\n",
        "Attention_mask = torch.Tensor(tokens_test['attention_mask'])\n",
        "Attention_mask = Attention_mask.type(torch.int64)\n",
        "Input_id=Input_id.to(cuda0)\n",
        "Attention_mask=Attention_mask.to(cuda0)\n",
        "\n",
        "#Print the variables\n",
        "print(model(Input_id,Attention_mask))\n",
        "print(df.head(20))"
      ],
      "metadata": {
        "id": "6BxWEFVXDtmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## HERE WE MAKING PREDICTIONS\n",
        "\n",
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "-MjUxPoSDxfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "\n",
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "id": "EiDm1VFhD1Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Label = [' Model', 'Batch', 'Epoch ', \"Specificity\",'accuracy']\n",
        "B1 = ['BERT', '32', '10 ','0.26']\n",
        "B2 = ['BERT', '1000', '1000', '0.32']\n",
        "B3 = ['BERT', '1000', '100','Tokenization=50', '0.33' ] \n",
        "B4 = ['BERT', '10000', '50','Tokenization=100', '0.35' ]\n",
        "B5 = ['BERT', '1000', '300', 'Tokenization=100', '0.40'] \n",
        "table_merge_1 = pd.DataFrame([B1, B2, B3, B4, B5],columns=Label)\n",
        "table_merge_1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lJX-XPz7VLNL",
        "outputId": "abf081cc-5330-47d4-ae77-e717cfb5f8ac"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Model  Batch Epoch        Specificity accuracy\n",
              "0   BERT     32    10               0.26     None\n",
              "1   BERT   1000   1000              0.32     None\n",
              "2   BERT   1000    100   Tokenization=50     0.33\n",
              "3   BERT  10000     50  Tokenization=100     0.35\n",
              "4   BERT   1000    300  Tokenization=100     0.40"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4380606-068d-46a9-89bf-dba95970fadf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Batch</th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BERT</td>\n",
              "      <td>32</td>\n",
              "      <td>10</td>\n",
              "      <td>0.26</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BERT</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.32</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BERT</td>\n",
              "      <td>1000</td>\n",
              "      <td>100</td>\n",
              "      <td>Tokenization=50</td>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BERT</td>\n",
              "      <td>10000</td>\n",
              "      <td>50</td>\n",
              "      <td>Tokenization=100</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BERT</td>\n",
              "      <td>1000</td>\n",
              "      <td>300</td>\n",
              "      <td>Tokenization=100</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4380606-068d-46a9-89bf-dba95970fadf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4380606-068d-46a9-89bf-dba95970fadf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4380606-068d-46a9-89bf-dba95970fadf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results of our Models:"
      ],
      "metadata": {
        "id": "EL86zRLtah0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Label = [' Model', 'CV', 'Solver', 'Specifity', 'max_iter', 'Accuracy']\n",
        "LR_1 = ['Log_Reg', '2', 'lbfgs','Basic model', '10','0.4635']\n",
        "LR_2 = ['Log_Reg', '2', 'lbfgs','Label encoded Y','10', '0.4635']\n",
        "LR_3 = ['Log_Reg', '5', 'lbfgs','Label encoded Y','10', '0.4625'] \n",
        "LR_4 = ['Log_Reg', '5', 'lbfgs','Label encoded Y','100', '0.4677']\n",
        "LR_5 = ['Log_Reg', '5', 'newton-cg','Label encoded Y','100','0.46770'] \n",
        "LR_5 = ['Log_Reg', '5', 'lbfgs','Label encoded Y','100','0.47083'] \n",
        "LR_6 = ['Log_Reg', '10', 'lbfgs','Label encoded Y','500','0.55208'] \n",
        "\n",
        "table_merge = pd.DataFrame([LR_1, LR_2, LR_3, LR_4, LR_5, LR_6],columns=Label)\n",
        "table_merge\n",
        "\n",
        "Label = [' Model', \"Specificity\",'accuracy']\n",
        "M1 = ['Naives Bayes', '','0.4823']\n",
        "M2 = ['Naives Bayes',  'Train Set= 0.9','0.5166']\n",
        "M3=['SVM',  '', '0.4583']\n",
        "M4 =['SVM','Train set=0.9', '0.5270']\n",
        "M5 =['SVM','Train set=0.9 & Random state= 77777', '0.5229']\n",
        "table_merge_2 = pd.DataFrame([M1, M2, M3, M4, M5],columns=Label)\n",
        "table_merge_2\n",
        "\n",
        "Label = [' Model', 'Batch', 'Epoch ', \"Specificity\",'accuracy']\n",
        "B1 = ['BERT', '32', '10 ','0.26']\n",
        "B2 = ['BERT', '1000', '1000', '0.32']\n",
        "B3 = ['BERT', '1000', '100','Tokenization=50', '0.33' ] \n",
        "B4 = ['BERT', '10000', '50','Tokenization=100', '0.35' ]\n",
        "B5 = ['BERT', '1000', '300', 'Tokenization=100', '0.40'] \n",
        "table_merge_1 = pd.DataFrame([B1, B2, B3, B4, B5],columns=Label)\n",
        "table_merge_1\n",
        "\n",
        "tables = [table_merge, table_merge_1, table_merge_2]\n",
        "tables = pd.concat(tables).reset_index()\n",
        "tables"
      ],
      "metadata": {
        "id": "WYWcHT3YaoVz",
        "outputId": "819a15a0-54c3-4e8f-b989-6de749cf3c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    index         Model   CV Solver        Specifity max_iter Accuracy  Batch  \\\n",
              "0       0       Log_Reg    2  lbfgs      Basic model       10   0.4635    NaN   \n",
              "1       1       Log_Reg    2  lbfgs  Label encoded Y       10   0.4635    NaN   \n",
              "2       2       Log_Reg    5  lbfgs  Label encoded Y       10   0.4625    NaN   \n",
              "3       3       Log_Reg    5  lbfgs  Label encoded Y      100   0.4677    NaN   \n",
              "4       4       Log_Reg    5  lbfgs  Label encoded Y      100  0.47083    NaN   \n",
              "5       5       Log_Reg   10  lbfgs  Label encoded Y      500  0.55208    NaN   \n",
              "6       0          BERT  NaN    NaN              NaN      NaN      NaN     32   \n",
              "7       1          BERT  NaN    NaN              NaN      NaN      NaN   1000   \n",
              "8       2          BERT  NaN    NaN              NaN      NaN      NaN   1000   \n",
              "9       3          BERT  NaN    NaN              NaN      NaN      NaN  10000   \n",
              "10      4          BERT  NaN    NaN              NaN      NaN      NaN   1000   \n",
              "11      0  Naives Bayes  NaN    NaN              NaN      NaN      NaN    NaN   \n",
              "12      1  Naives Bayes  NaN    NaN              NaN      NaN      NaN    NaN   \n",
              "13      2           SVM  NaN    NaN              NaN      NaN      NaN    NaN   \n",
              "14      3           SVM  NaN    NaN              NaN      NaN      NaN    NaN   \n",
              "15      4           SVM  NaN    NaN              NaN      NaN      NaN    NaN   \n",
              "\n",
              "   Epoch                           Specificity accuracy  \n",
              "0     NaN                                  NaN      NaN  \n",
              "1     NaN                                  NaN      NaN  \n",
              "2     NaN                                  NaN      NaN  \n",
              "3     NaN                                  NaN      NaN  \n",
              "4     NaN                                  NaN      NaN  \n",
              "5     NaN                                  NaN      NaN  \n",
              "6     10                                  0.26     None  \n",
              "7    1000                                 0.32     None  \n",
              "8     100                      Tokenization=50     0.33  \n",
              "9      50                     Tokenization=100     0.35  \n",
              "10    300                     Tokenization=100     0.40  \n",
              "11    NaN                                        0.4823  \n",
              "12    NaN                       Train Set= 0.9   0.5166  \n",
              "13    NaN                                        0.4583  \n",
              "14    NaN                        Train set=0.9   0.5270  \n",
              "15    NaN  Train set=0.9 & Random state= 77777   0.5229  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4a5a789-83f4-4b14-82da-7f1df1fa956e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Model</th>\n",
              "      <th>CV</th>\n",
              "      <th>Solver</th>\n",
              "      <th>Specifity</th>\n",
              "      <th>max_iter</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Batch</th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Log_Reg</td>\n",
              "      <td>2</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>Basic model</td>\n",
              "      <td>10</td>\n",
              "      <td>0.4635</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Log_Reg</td>\n",
              "      <td>2</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>Label encoded Y</td>\n",
              "      <td>10</td>\n",
              "      <td>0.4635</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Log_Reg</td>\n",
              "      <td>5</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>Label encoded Y</td>\n",
              "      <td>10</td>\n",
              "      <td>0.4625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Log_Reg</td>\n",
              "      <td>5</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>Label encoded Y</td>\n",
              "      <td>100</td>\n",
              "      <td>0.4677</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Log_Reg</td>\n",
              "      <td>5</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>Label encoded Y</td>\n",
              "      <td>100</td>\n",
              "      <td>0.47083</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Log_Reg</td>\n",
              "      <td>10</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>Label encoded Y</td>\n",
              "      <td>500</td>\n",
              "      <td>0.55208</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>BERT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32</td>\n",
              "      <td>10</td>\n",
              "      <td>0.26</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>BERT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.32</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>BERT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000</td>\n",
              "      <td>100</td>\n",
              "      <td>Tokenization=50</td>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>BERT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10000</td>\n",
              "      <td>50</td>\n",
              "      <td>Tokenization=100</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4</td>\n",
              "      <td>BERT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000</td>\n",
              "      <td>300</td>\n",
              "      <td>Tokenization=100</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>Naives Bayes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>0.4823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>Naives Bayes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train Set= 0.9</td>\n",
              "      <td>0.5166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>SVM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>0.4583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3</td>\n",
              "      <td>SVM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train set=0.9</td>\n",
              "      <td>0.5270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4</td>\n",
              "      <td>SVM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Train set=0.9 &amp; Random state= 77777</td>\n",
              "      <td>0.5229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4a5a789-83f4-4b14-82da-7f1df1fa956e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4a5a789-83f4-4b14-82da-7f1df1fa956e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4a5a789-83f4-4b14-82da-7f1df1fa956e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Project_guidelines_2022.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}