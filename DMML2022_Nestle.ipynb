{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stergios-Konstantinidis/DMML2022_Nestle/blob/main/DMML2022_Nestle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZKqCFFbNZ04"
      },
      "source": [
        "# Data Mining and Machine Learning - Project\n",
        "\n",
        "## Detecting Difficulty Level of French Texts\n",
        "\n",
        "### Step by step guidelines\n",
        "\n",
        "The following are a set of step by step guidelines to help you get started with your project for the Data Mining and Machine Learning class. \n",
        "To test what you learned in the class, we will hold a competition. You will create a classifier that predicts how the level of some text in French (A1,..., C2). The team with the highest rank will get some goodies in the last class (some souvenirs from tech companies: Amazon, LinkedIn, etc).\n",
        "\n",
        "**2 people per team**\n",
        "\n",
        "Choose a team here:\n",
        "https://moodle.unil.ch/mod/choicegroup/view.php?id=1305831\n",
        "\n",
        "\n",
        "#### 1. üìÇ Create a public GitHub repository for your team using this naming convention `DMML2022_[your_team_name]` with the following structure:\n",
        "- data (folder) \n",
        "- code (folder) \n",
        "- documentation (folder)\n",
        "- a readme file (.md): *mention team name, participants, brief description of the project, approach, summary of results table and link to the explainatory video (see below).*\n",
        "\n",
        "All team members should contribute to the GitHub repository.\n",
        "\n",
        "#### 2. üá∞ Join the competititon on Kaggle using the invitation link we sent on Slack.\n",
        "\n",
        "Under the Team tab, save your team name (`UNIL_your_team_name`) and make sure your team members join in as well. You can merge your user account with your teammates in order to create a team.\n",
        "\n",
        "#### 3. üìì Read the data into your colab notebook. There should be one code notebook per team, but all team members can participate and contribute code. \n",
        "\n",
        "You can use either direct the Kaggle API and your Kaggle credentials (as explained below and **entirely optional**), or dowload the data form Kaggle and upload it onto your team's GitHub repository under the data subfolder.\n",
        "\n",
        "#### 4. üíé Train your models and upload the code under your team's GitHub repo. Set the `random_state=0`.\n",
        "- baseline\n",
        "- logistic regression with TFidf vectoriser (simple, no data cleaning)\n",
        "- KNN & hyperparameter optimisation (simple, no data cleaning)\n",
        "- Decision Tree classifier & hyperparameter optimisation (simple, no data cleaning)\n",
        "- Random Forests classifier (simple, no data cleaning)\n",
        "- another technique or combination of techniques of your choice\n",
        "\n",
        "BE CREATIVE! You can use whatever method you want, in order to climb the leaderboard. The only rule is that it must be your own work. Given that, you can use all the online resources you want. \n",
        "\n",
        "#### 5. üé• Create a YouTube video (10-15 minutes) of your solution and embed it in your notebook. Explain the algorithms used and the evaluation of your solutions. *Select* projects will also be presented live by the group during the last class.\n",
        "\n",
        "\n",
        "### Submission details (one per team)\n",
        "\n",
        "1. Download a ZIPped file of your team's repository and submit it in Moodle here. IMPORTANT: in the comment of the submission, insert a link to the repository on Github.\n",
        "https://moodle.unil.ch/mod/assign/view.php?id=1305833\n",
        "\n",
        "\n",
        "\n",
        "### Grading (one per team)\n",
        "- 20% Kaggle Rank\n",
        "- 50% code quality (using classes, splitting into proper files, documentation, etc)\n",
        "- 15% github quality (include link to video, table with progress over time, organization of code, images, etc)\n",
        "- 15% video quality (good sound, good slides, interesting presentation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-14CAdOoinM"
      },
      "source": [
        "## Some further details for points 3 and 4 above.\n",
        "\n",
        "### 3. Read data into your notebook with the Kaggle API (optional but useful). \n",
        "\n",
        "You can also download the data from Kaggle and put it in your team's repo the data folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ_hnJzSNO2g",
        "outputId": "4630a8ad-955a-4c6e-e639-e16c4e078434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# reading in the data via the Kaggle API\n",
        "\n",
        "# mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJPTz3D7TeQv",
        "outputId": "2fe882cb-3fb8-4738-ab0e-df0373c21f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "# install Kaggle\n",
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKG1TCddRYTB"
      },
      "source": [
        "### IMPORTANT\n",
        "Log into your Kaggle account, go to Account > API > Create new API token. You will obtain a kaggle.json file. Save it in your Google Drive (not in a folder, in your general drive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JgzLj451YDfV"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KrsZLalrSI3u"
      },
      "outputs": [],
      "source": [
        "#read in your Kaggle credentials from Google Drive\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-ETUrrhgdnfU"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BDI60LXKTPzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d8d249-7392-4231-b7ff-8db4fc88b4e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading detecting-french-texts-difficulty-level-2022.zip to /content\n",
            "100% 303k/303k [00:00<00:00, 501kB/s]\n",
            "100% 303k/303k [00:00<00:00, 500kB/s]\n",
            "Archive:  detecting-french-texts-difficulty-level-2022.zip\n",
            "  inflating: data/sample_submission.csv  \n",
            "  inflating: data/training_data.csv  \n",
            "  inflating: data/unlabelled_test_data.csv  \n"
          ]
        }
      ],
      "source": [
        "# download the dataset from the competition page\n",
        "\n",
        "try:\n",
        "  df = pd.read_csv('/content/data/training_data.csv')\n",
        "except:\n",
        "  !kaggle competitions download -c detecting-french-texts-difficulty-level-2022\n",
        "  !unzip \"detecting-french-texts-difficulty-level-2022.zip\" -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "daqvj7feTx60"
      },
      "outputs": [],
      "source": [
        "# read in your training data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn \n",
        "#import sklearn.model_selection\n",
        "\n",
        "df = pd.read_csv('/content/data/training_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VxRSnk5bhTp8",
        "outputId": "dc9c762d-605f-441a-aa03-df89fd12c282"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence difficulty\n",
              "0   0  Les co√ªts kilom√©triques r√©els peuvent diverger...         C1\n",
              "1   1  Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...         A1\n",
              "2   2  Le test de niveau en fran√ßais est sur le site ...         A1\n",
              "3   3           Est-ce que ton mari est aussi de Boston?         A1\n",
              "4   4  Dans les √©coles de commerce, dans les couloirs...         B1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c820e7a-80b6-4e2a-abef-816f8312398b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les co√ªts kilom√©triques r√©els peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en fran√ßais est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les √©coles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c820e7a-80b6-4e2a-abef-816f8312398b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c820e7a-80b6-4e2a-abef-816f8312398b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c820e7a-80b6-4e2a-abef-816f8312398b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kpfbtndj0jL"
      },
      "source": [
        "Have a look at the data on which to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7G75Q1gRj49l",
        "outputId": "0b43c997-cc8f-42c9-f604-e2d726a5dd89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence\n",
              "0   0  Nous d√ªmes nous excuser des propos que nous e√ª...\n",
              "1   1  Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
              "2   2  Et, paradoxalement, boire froid n'est pas la b...\n",
              "3   3  Ce n'est pas √©tonnant, car c'est une saison my...\n",
              "4   4  Le corps de Golo lui-m√™me, d'une essence aussi..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de0e53b1-9a8b-4b1c-8f75-6c5fd4f74a3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous d√ªmes nous excuser des propos que nous e√ª...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ce n'est pas √©tonnant, car c'est une saison my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Le corps de Golo lui-m√™me, d'une essence aussi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de0e53b1-9a8b-4b1c-8f75-6c5fd4f74a3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de0e53b1-9a8b-4b1c-8f75-6c5fd4f74a3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de0e53b1-9a8b-4b1c-8f75-6c5fd4f74a3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_pred = pd.read_csv('/content/data/unlabelled_test_data.csv')\n",
        "df_pred.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a37hWJ_ckBlk"
      },
      "source": [
        "And this is the format for your submissions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gk9H2dLHkFBa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "907f82da-2dee-45ed-e1af-aaf06a518e9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id difficulty\n",
              "0   0         A1\n",
              "1   1         A1\n",
              "2   2         A1\n",
              "3   3         A1\n",
              "4   4         A1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27bce6ef-5cf8-4958-ac47-b39d6642cc3b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27bce6ef-5cf8-4958-ac47-b39d6642cc3b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-27bce6ef-5cf8-4958-ac47-b39d6642cc3b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-27bce6ef-5cf8-4958-ac47-b39d6642cc3b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_example_submission = pd.read_csv('/content/data/sample_submission.csv')\n",
        "df_example_submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfTgL1erjqQ6"
      },
      "source": [
        "### 4. Train your models\n",
        "\n",
        "Set your X and y variables. \n",
        "Set the `random_state=0`\n",
        "Split the data into a train and test set using the following parameters `train_test_split(X, y, test_size=0.2, random_state=0)`.\n",
        "\n",
        "#### 4.1.Baseline\n",
        "What is the baseline for this classification problem?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install -U scikit-learn\n",
        "#pip install numpy \n",
        "#pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "1sqqpuY8PZbR",
        "outputId": "ab87b8d5-8e21-4357-d815-2176d93d8290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-79-1c878eef98a6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install -U scikit-learn\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVEaPzxuQFxg",
        "outputId": "1cc80f6d-0497-4cf3-d058-bca7bf5090b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvw9eWR4QLM6",
        "outputId": "b7e59485-417f-4e54-c8c3-38dc54b2d978"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTS\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
        "import spacy.cli\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
        "import numpy as np\n",
        "from sklearn import linear_model, decomposition, datasets\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "EXJ03SkaWj4N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "t4O_pYiHpiRd"
      },
      "outputs": [],
      "source": [
        "np.random.seed = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WDdFr4xsk5Qf"
      },
      "outputs": [],
      "source": [
        "#Split data set\n",
        "\n",
        "X= df['sentence']\n",
        "y= df['difficulty']\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlvbPYa0k78l"
      },
      "source": [
        "#### 4.2. Logistic Regression (without data cleaning)\n",
        "\n",
        "Train a simple logistic regression model using a Tfidf vectoriser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEe3-QNlow4H"
      },
      "outputs": [],
      "source": [
        "\n",
        "texts = df['sentence']\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
        "features = tfidf.fit_transform(texts)\n",
        "pd.DataFrame(\n",
        "    features.todense(),\n",
        "    columns=tfidf.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)"
      ],
      "metadata": {
        "id": "i529gMyojD1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ-qO8C5oyov"
      },
      "source": [
        "Calculate accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot encoder ou label encoder \n",
        "\n",
        "df['oe_difficulty'] = ['0' if x == 'A1'\n",
        "                   else '1' if x =='A2'\n",
        "                   else '2' if x == 'B1'\n",
        "                   else '3' if x=='B2'\n",
        "                   else '4' if x== 'C1'\n",
        "                   else '5'\n",
        "                   for x in df.difficulty]\n",
        "\n",
        "df.oe_difficulty.value_counts()\n",
        "newY = df['oe_difficulty']\n",
        "\n",
        "X= df['sentence']\n",
        "newY = df['oe_difficulty']\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, newY, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "muF_24BsZ1ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)"
      ],
      "metadata": {
        "id": "gCQDcch4bXKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PViIQdnDpASy"
      },
      "outputs": [],
      "source": [
        "LR = LogisticRegressionCV(solver='lbfgs', cv=16, max_iter=1000, random_state = 50)\n",
        "\n",
        "LR.fit(X_train_text, y_train)\n",
        "\n",
        "LR.score(X_train_text, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accur_test_LR = LR.score(X_test_text, y_test)\n",
        "accur_test_LR"
      ],
      "metadata": {
        "id": "c1-dsTH4j4fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = LR.predict(X_test_text)\n",
        "precision_score_LR_test =  \"Precision Score : \",precision_score(y_test, y_pred, \n",
        "                                           pos_label='positive',\n",
        "                                           average='micro')\n",
        "recall_score_LR_test = \"Recall Score : \",recall_score(y_test, y_pred, \n",
        "                                           pos_label='positive',\n",
        "                                           average='micro')\n",
        "print(precision_score_LR_test)\n",
        "print(recall_score_LR_test)"
      ],
      "metadata": {
        "id": "hS-CY6xF_mWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for text in X_test_text:\n",
        "  print((X_test.reset_index())._get_value(i, \"sentence\", takeable=False) + \"  \" + LR.predict(text))\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "1gQPHn8pV0pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.read_csv('/content/data/unlabelled_test_data.csv')\n",
        "df_pred_text = text_transformer.transform(df_pred[\"sentence\"])\n",
        "\n",
        "df_pred['difficulty'] = list(map(lambda x : LR.predict(x)[0], df_pred_text))\n",
        "\n",
        "df_pred = df_pred[[\"id\", \"difficulty\"]]\n",
        "df_pred = df_pred.set_index('id')\n",
        "\n",
        "df_pred.to_csv('file_name.csv')\n",
        "df_pred.head()\n"
      ],
      "metadata": {
        "id": "MghtmHHlURok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D3_dp3apcmr"
      },
      "source": [
        "Have a look at the confusion matrix and identify a few examples of sentences that are not well classified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TTEiuXasNFg"
      },
      "source": [
        "Generate your first predictions on the `unlabelled_test_data.csv`. make sure your predictions match the format of the `unlabelled_test_data.csv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXG_yIG_pQ8t"
      },
      "source": [
        "#### 4.3. KNN (without data cleaning)\n",
        "\n",
        "Train a KNN classification model using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPRjD1rSqKKZ"
      },
      "outputs": [],
      "source": [
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot encoder ou label encoder \n",
        "\n",
        "df['oe_difficulty'] = ['0' if x == 'A1'\n",
        "                   else '1' if x =='A2'\n",
        "                   else '2' if x == 'B1'\n",
        "                   else '3' if x=='B2'\n",
        "                   else '4' if x== 'C1'\n",
        "                   else '5'\n",
        "                   for x in df.difficulty]\n",
        "\n",
        "df.oe_difficulty.value_counts()\n",
        "newY = df['oe_difficulty']\n",
        "\n",
        "X= df['sentence']\n",
        "newY = df['oe_difficulty']\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, newY, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "4y9EVvgqZJSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6rH2Hx0qtB2"
      },
      "source": [
        "Try to improve it by tuning the hyper parameters (`n_neighbors`,   `p`, `weights`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRy18Ce_qxPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d5757b6-117f-4630-8930-2cc81dae67d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 19 candidates, totalling 190 fits\n"
          ]
        }
      ],
      "source": [
        "#KNN with 6 neightbors accuracy 0.2073\n",
        "#KNN with 8 Neightbors accuracy 0.2073\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "#K in range from 1 to 8\n",
        "k_range = list(range(1, 20))\n",
        "param_grid = dict(n_neighbors=k_range)\n",
        "\n",
        "# defining parameter range\n",
        "knn_cv = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
        "  \n",
        "# fitting the model for grid search\n",
        "knn_cv.fit(X_train_text, y_train)\n",
        "\n",
        "y_pred_knn = knn_cv.predict(X_test_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN with minkowski and algorithm brute give us accuracy of: 0.1719\n",
        "KNeighborsClassifier(algorithm='brute', leaf_size=10, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
        "                     weights='uniform')\n",
        "knn.fit(X_train_text, y_train)\n",
        "\n",
        "y_pred_knn = knn.predict(X_test_text)"
      ],
      "metadata": {
        "id": "0PV9gUSySFY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_test = knn.score(X_test_text, y_test)\n",
        "knn_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eFtTuV2ZU0Y",
        "outputId": "3f5d833d-ad39-474e-b79a-d7a2a2f6c094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3229166666666667"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.32291"
      ],
      "metadata": {
        "id": "y1C6ssd9Zu_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#avec micro partout la meme valeur 0.2073\n",
        "#avec macro Precision , recall et Score different\n",
        "def evaluate(test, pred):\n",
        "  precision = precision_score(test, pred, pos_label='positive',\n",
        "                                           average='macro')\n",
        "  recall = recall_score(test, pred, pos_label='positive',\n",
        "                                           average='macro')\n",
        "  f1= f1_score(test, pred, pos_label='positive',\n",
        "                                           average='macro')\n",
        "  print(f\"ACCURACY SCORE:\\n{accuracy_score(test, pred) :.4f}\")\n",
        "  print(f'CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}')\n",
        "\n",
        "evaluate(y_test, y_pred_knn)"
      ],
      "metadata": {
        "id": "Gb7hfqgVXuXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5112e7-0a8c-47b6-f682-07095ada8b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY SCORE:\n",
            "0.3229\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3927\n",
            "\tRecall: 0.3232\n",
            "\tF1_Score: 0.3076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  average_options = (None, \"micro\", \"macro\", \"weighted\", \"samples\")\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  average_options = (None, \"micro\", \"macro\", \"weighted\", \"samples\")\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  average_options = (None, \"micro\", \"macro\", \"weighted\", \"samples\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFNH1WgNqc62"
      },
      "source": [
        "#### 4.4. Decision Tree Classifier (without data cleaning)\n",
        "\n",
        "Train a Decison Tree classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQHjvOp7q11L"
      },
      "source": [
        "Try to improve it by tuning the hyper parameters (`max_depth`, the depth of the decision tree)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Fzl5BUq8JN"
      },
      "outputs": [],
      "source": [
        "# first we tried depth 10, and accuracy of 0.1885\n",
        "# with deph=16 we have accuracy =0.1969\n",
        "# with deph=26 accuracy = 0.2042\n",
        "# wuth deph =40. accuracy=0.2021\n",
        "\n",
        "tree = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
        "                       max_depth=4000, \n",
        "                       random_state=50)\n",
        "tree.fit(X_train_text, y_train)\n",
        "y_pred_tree = tree.predict(X_test_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(train, pred):\n",
        "  precision = precision_score(train, pred,pos_label='positive',\n",
        "                                           average='micro')\n",
        "  recall = recall_score(train, pred,pos_label='positive',\n",
        "                                           average='micro')\n",
        "  f1= f1_score(train, pred,pos_label='positive',\n",
        "                                           average='micro')\n",
        "  print(f\"ACCURACY SCORE:\\n{accuracy_score(train, pred) :.4f}\")\n",
        "  print(f'CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}')\n",
        "evaluate(y_test, y_pred_tree)"
      ],
      "metadata": {
        "id": "0hGXj6RaaSAU",
        "outputId": "bac47f96-78d7-4a50-ab6d-ed8a32a3c6e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY SCORE:\n",
            "0.3021\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3021\n",
            "\tRecall: 0.3021\n",
            "\tF1_Score: 0.3021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M52Ys3hcq7ku"
      },
      "source": [
        "#### 4.5. Random Forest Classifier (without data cleaning)\n",
        "\n",
        "Try a Random Forest Classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#One hot encoder ou label encoder \n",
        "\n",
        "df['oe_difficulty'] = ['0' if x == 'A1'\n",
        "                   else '1' if x =='A2'\n",
        "                   else '2' if x == 'B1'\n",
        "                   else '3' if x=='B2'\n",
        "                   else '4' if x== 'C1'\n",
        "                   else '5'\n",
        "                   for x in df.difficulty]\n",
        "\n",
        "df.oe_difficulty.value_counts()\n",
        "newY = df['oe_difficulty']\n",
        "\n",
        "X= df['sentence']\n",
        "newY = df['oe_difficulty']\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, newY, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "hMgVlrBb-wTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['sentence']\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
        "features = tfidf.fit_transform(texts)\n",
        "pd.DataFrame(\n",
        "    features.todense(),\n",
        "    columns=tfidf.get_feature_names())"
      ],
      "metadata": {
        "id": "gw_8yLbsAvuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)"
      ],
      "metadata": {
        "id": "6ptuGy7SBE_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "## Doesnt work because it's for continuous varibale like housing price \n",
        "\n",
        "#rf = RandomForestRegressor(random_state = 42)\n",
        "#from pprint import pprint\n",
        "# Look at parameters used by our current forest\n",
        "#print('Parameters currently in use:\\n')\n",
        "#pprint(rf.get_params())"
      ],
      "metadata": {
        "id": "zbvloIiy7coB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)"
      ],
      "metadata": {
        "id": "OcJh0i-y7krX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf408f6-5b4e-4378-b4ab-acfa61d5d089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "\n",
        "# Accuracy less than 50\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_clf = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 4, cv = 2, verbose=1, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_clf.fit(X_train_text, y_train)"
      ],
      "metadata": {
        "id": "8XZqDNxD7oFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf_test = rf_clf.score(X_test_text, y_test)\n",
        "rf_clf_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug4FBMTZUlAU",
        "outputId": "aa0b1048-335b-42a3-9967-d5c90c24db52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40625"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##Marche beaucoup moins bien\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_clf = RandomForestClassifier(criterion='gini',\n",
        "                                 n_estimators=5,\n",
        "                                 random_state=42,\n",
        "                                 n_jobs=20,\n",
        "                                max_depth=40,\n",
        "                                min_samples_split=5,\n",
        "                                max_features=30000,\n",
        "                                bootstrap = bool,\n",
        "                                oob_score= bool,\n",
        "                                warm_start= bool)\n",
        "# Fit the random search model\n",
        "rf_clf.fit(X_train_text, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkEw2RuzUAi7",
        "outputId": "5e2a23e1-818d-4c76-f2b0-bb0034f15dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:560: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
            "  # axis to be consistent with the classification case and make\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=<class 'bool'>, max_depth=40,\n",
              "                       max_features=30000, min_samples_split=5, n_estimators=5,\n",
              "                       n_jobs=20, oob_score=<class 'bool'>, random_state=42,\n",
              "                       warm_start=<class 'bool'>)"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf_test = rf_clf.score(X_test_text, y_test)\n",
        "rf_clf_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ebo8JJYXFyf",
        "outputId": "6ca54cc5-3f40-48a5-ceb4-57f6afbd078f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.325"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "pTPHTA-8C4jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf_test = rf_clf.score(X_test_text, y_test)\n",
        "rf_clf_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1jk8RyOBwsN",
        "outputId": "0d19dfff-fc8b-4c99-a499-f2f476111991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40625"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_features, test_labels):\n",
        "    predictions = model.predict(test_features)\n",
        "    errors = abs(predictions - test_labels)\n",
        "    mape = 100 * np.mean(errors / test_labels)\n",
        "    accuracy = 100 - mape\n",
        "    print('Model Performance')\n",
        "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
        "base_model.fit(X_train_text, y_train)\n",
        "base_accuracy = evaluate(base_model, X_test_text, y_test)\n",
        "\n",
        "\n",
        "best_random = rf_random.best_estimator_\n",
        "random_accuracy = evaluate(best_random, X_test_text, y_test)\n",
        "\n",
        "\n",
        "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))\n"
      ],
      "metadata": {
        "id": "1BW7KfuTBsvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestRegressor()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                          cv = 3, n_jobs = -1, verbose = 2)\n",
        "grid_search = GridSearchCV(estimator = RandomForestRegressor(), param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
        "grid_search.fit(X_train_text, y_train)\n",
        "grid_search.best_params_\n",
        "best_grid = grid_search.best_estimator_\n",
        "grid_accuracy = evaluate(best_grid, X_test_text, y_test)\n",
        "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))"
      ],
      "metadata": {
        "id": "8ANhf-Eg7MlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sssF4NIGrNLa",
        "outputId": "13308591-ea2e-464a-8a62-43adeada6d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-b5306b7fed00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                           \u001b[0;31m#n_informative=2, n_redundant=0,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           \u001b[0;31m#random_state=0, shuffle=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RandomForestRegressor' is not defined"
          ]
        }
      ],
      "source": [
        "#X, y = make_classification(n_samples=1000, n_features=4,\n",
        "                          #n_informative=2, n_redundant=0,\n",
        "                          #random_state=0, shuffle=False)\n",
        "\n",
        "\n",
        "clf = RandomForestClassifier(random_state=0, bootstrap= True, max_depth= 80,\n",
        " max_features= 3, min_samples_leaf =5, n_estimators= 100)\n",
        "\n",
        "clf.fit(X_train_text, y_train)\n",
        "RandomForestClassifier(...)\n",
        "\n",
        "y_pred_forest =  clf.predict(X_test_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(train, pred):\n",
        "  precision = precision_score(train, pred,pos_label='positive',\n",
        "                                           average='micro')\n",
        "  recall = recall_score(train, pred,pos_label='positive',\n",
        "                                           average='micro')\n",
        "  f1= f1_score(train, pred,pos_label='positive',\n",
        "                                           average='micro')\n",
        "  print(f'CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}')\n",
        "evaluate(y_test, y_pred_forest)"
      ],
      "metadata": {
        "id": "K1F5ZCGgcjeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7329656e-bb39-4fb5-d1b0-2d75391c001e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.1646\n",
            "\tRecall: 0.1646\n",
            "\tF1_Score: 0.1646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(X_train_text, y_train)\n",
        "accur_train_forest = clf.score(X_train_text, y_train)\n",
        "accur_train_forest"
      ],
      "metadata": {
        "id": "u8qnuSbjaV_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(X_test_text, y_pred)\n",
        "accur_test_forest = clf.score(X_test_text, y_test)\n",
        "accur_test_forest"
      ],
      "metadata": {
        "id": "xpjEP1YtbCGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-8_3MK1rpZr"
      },
      "source": [
        "#### 4.6. Any other technique, including data cleaning if necessary\n",
        "\n",
        "Try to improve accuracy by training a better model using the techniques seen in class, or combinations of them.\n",
        "\n",
        "As usual, show the accuracy, precision, recall and f1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX5AjvvKr_nW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "9e21f7c7-4a4a-4d5c-b0ed-cc8eb1d69098"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence difficulty\n",
              "0   0  Les co√ªts kilom√©triques r√©els peuvent diverger...         C1\n",
              "1   1  Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...         A1\n",
              "2   2  Le test de niveau en fran√ßais est sur le site ...         A1\n",
              "3   3           Est-ce que ton mari est aussi de Boston?         A1\n",
              "4   4  Dans les √©coles de commerce, dans les couloirs...         B1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e257800b-bbdb-4c5e-8790-0e1c3121e7d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les co√ªts kilom√©triques r√©els peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en fran√ßais est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les √©coles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e257800b-bbdb-4c5e-8790-0e1c3121e7d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e257800b-bbdb-4c5e-8790-0e1c3121e7d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e257800b-bbdb-4c5e-8790-0e1c3121e7d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first let's check if there are NA's\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gIJjicHh2B_",
        "outputId": "9fefab04-6e80-4ffa-ea54-0fd13acec6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id            0\n",
              "sentence      0\n",
              "difficulty    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le_diff = pd.Series(LabelEncoder().fit_transform(df[\"difficulty\"]), name=\"le_diff\")\n",
        "le_diff"
      ],
      "metadata": {
        "id": "jC8R5PMViQDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7360edbf-541b-4f60-ef4c-736bba19ea43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       4\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       2\n",
              "       ..\n",
              "4795    3\n",
              "4796    4\n",
              "4797    1\n",
              "4798    5\n",
              "4799    5\n",
              "Name: le_diff, Length: 4800, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82FvnJycsBFf"
      },
      "source": [
        "#### 4.7. Show a summary of your results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tableau_data = {'Logistic Regression': [0.565376, accur_test_LR, accur_train_LR,  precision_score_LR_train, recall_score_LR_train],\n",
        "        'KNN': [0.565376, accur_test_KNN , accur_train_KNN, precision_score_KNN, recall_score_KNN],\n",
        "        'Decision Tree' : [accur_test_tree, accur_train_tree, precision_score_tree, recall_score_tree]\n",
        "        'Random Forest': [accur_test_forest, accur_train_forest, precision_score_forest, recall_score_forest]}\n",
        "  \n",
        "# Creates pandas DataFrame.\n",
        "tableau_df = pd.DataFrame(tableau_data, index=[ 'Base rate', 'Accuracy Test',\n",
        "                               'Accuracy Train',\n",
        "                               'Precision',\n",
        "                               'Recall'])\n",
        "\n",
        "tableau_df"
      ],
      "metadata": {
        "id": "GtoMd99OU9lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the encoder\n",
        "oe=OrdinalEncoder()\n",
        "\n",
        "# set the order of your categories\n",
        "oe.set_params(categories= [['0', '1', '2', '3', '4','5']])\n",
        "\n",
        "# fit-transform a dataframe of the categorical age variable\n",
        "oe_difficulty =oe.fit_transform(df[['oe_difficulty']])\n",
        "\n",
        "#number of values per class\n",
        "oe_difficulty = pd.DataFrame(oe_difficulty).astype('int')\n",
        "oe_difficulty.value_counts()"
      ],
      "metadata": {
        "id": "-8FFD5uDy-fv",
        "outputId": "cc73fc6d-753d-47fc-97bb-abd0bce2f2e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    813\n",
              "5    807\n",
              "4    798\n",
              "1    795\n",
              "2    795\n",
              "3    792\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### NEW TEST\n",
        "\n",
        "#Encode Data\n",
        "df['oe_difficulty'] = [0 if x == 'A1'\n",
        "                   else 2 if x =='A2'\n",
        "                   else 1 if x== 'B1'\n",
        "                   else 3 if x == 'B2'\n",
        "                   else 4 if x == 'C1'\n",
        "                   else 5\n",
        "                   for x in df.difficulty]\n",
        "df.drop(labels='difficulty', axis=1)\n",
        "\n",
        "#Encode column\n",
        "df.oe_difficulty.value_counts()\n",
        "newY = df['oe_difficulty']\n",
        "X= df['sentence']\n",
        "newY = df['oe_difficulty']\n",
        "\n",
        "#Encoded dataframe\n",
        "df_encoded= df.drop('difficulty', axis = 1)\n",
        "df_encoded\n",
        "\n",
        "#Vectorize\n",
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, newY, test_size=0.2, random_state=0)\n"
      ],
      "metadata": {
        "id": "6742PIoRdWpd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pca = decomposition.PCA()\n",
        "#std_slc = StandardScaler()\n",
        "#logistic_Reg = linear_model.LogisticRegression()\n",
        "#pipe = Pipeline(steps=[('std_slc', std_slc),\n",
        "                           #('pca', pca),\n",
        "                           #('logistic_Reg', logistic_Reg)])"
      ],
      "metadata": {
        "id": "KiEWpL8BZp4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PCA\n",
        "#from sklearn.decomposition import PCA\n",
        "#pca = PCA(n_components=2)\n",
        "#pca.fit(X_train_text)\n",
        "#PCA(n_components=2)\n",
        "#print(pca.explained_variance_ratio_)\n",
        "#print(pca.singular_values_)\n"
      ],
      "metadata": {
        "id": "NlTVkN0WbWbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##NEW TEST\n",
        "\n",
        "#Vectorize\n",
        "texts = df['sentence']\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
        "features = tfidf.fit_transform(texts)\n",
        "pd.DataFrame(\n",
        "    features.todense(),\n",
        "    columns=tfidf.get_feature_names())\n",
        "\n",
        "#Transform\n",
        "text_transformer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
        "X_train_text = text_transformer.fit_transform(X_train)\n",
        "X_test_text = text_transformer.transform(X_test)\n",
        "\n",
        "#Split \n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCd2BNvXY4DG",
        "outputId": "411c2f96-d98c-4a78-a0ae-5d01eefecf06"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR_cv = LogisticRegressionCV(solver='lbfgs', cv=10, max_iter=100, random_state = 0)\n",
        "\n",
        "LR_cv.fit(X_train_text, y_train)"
      ],
      "metadata": {
        "id": "HSwzwt_L0pNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87914eaf-9229-4653-99d7-58ffa023c424"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR_accur_test = LR_cv.score(X_test_text, y_test)\n",
        "LR_accur_test"
      ],
      "metadata": {
        "id": "E3qCkfbYgGBz",
        "outputId": "de2fde0c-7127-4e57-b605-aa411303a8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46458333333333335"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#solver='lbfgs', \n",
        "#cv=10, \n",
        "#max_iter=100, \n",
        "#random_state = 0)\n",
        "0.5520833333333334\n",
        "\n",
        "#With vectorizer\n",
        "#solver='lbfgs', \n",
        "#cv=10, \n",
        "#max_iter=100, \n",
        "#random_state = 0)\n",
        "0.5520833333333334\n",
        "\n",
        "\n",
        "#solver='newton-cholesky', \n",
        "#cv=10\n",
        "#max_iter=100, \n",
        "#random_state = 0)\n",
        "#took to much time\n",
        "\n",
        "\n",
        "#solver='lbfgs'\n",
        "# cv=10, \n",
        "#max_iter=100, \n",
        "#random_state = 0)\n",
        "0.46458333333333335\n",
        "\n",
        "\n",
        "#Vectorize\n",
        "#Encoded Y\n",
        "#solver='lbfgs'\n",
        "# cv=10, \n",
        "#max_iter=100, \n",
        "#random_state = 0)\n",
        "0.553125\n",
        "\n",
        "#Vectorize\n",
        "#Encoded Y TRUUUUUE\n",
        "#solver='lbfgs'\n",
        "# cv=10, \n",
        "#max_iter=100, \n",
        "#random_state = 0)\n",
        "0.46458333333333335"
      ],
      "metadata": {
        "id": "9ovRqV_5VeYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fcbe2f-04a6-4bac-c926-0135880d4bc1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.553125"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NEW TEST\n",
        "\n",
        "LR_cv = LogisticRegressionCV(solver='newton-cholesky', cv=10, max_iter=100, random_state = 0)\n",
        "\n",
        "LR_cv.fit(X_train_text, y_train)"
      ],
      "metadata": {
        "id": "NrdMx6FrUEJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_accur_test = LR_cv.score(X_test_text, y_test)\n",
        "LR_accur_test"
      ],
      "metadata": {
        "id": "6PPjWiz7VvBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###BERT MODEL\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "#Import bert model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Load the tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "oJQN5uoJXU4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_one = df.drop(['difficulty'], axis=1)\n",
        "df_one['oe_difficulty'].value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "S_FEeyS8keUb",
        "outputId": "d210faea-df3b-4686-d88d-2e22502d0cce"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                           sentence  oe_difficulty\n",
              "0        0  Les co√ªts kilom√©triques r√©els peuvent diverger...              4\n",
              "1        1  Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...              0\n",
              "2        2  Le test de niveau en fran√ßais est sur le site ...              0\n",
              "3        3           Est-ce que ton mari est aussi de Boston?              0\n",
              "4        4  Dans les √©coles de commerce, dans les couloirs...              1\n",
              "...    ...                                                ...            ...\n",
              "4795  4795  C'est pourquoi, il d√©cida de remplacer les hab...              3\n",
              "4796  4796  Il avait une de ces p√¢leurs splendides qui don...              4\n",
              "4797  4797  Et le premier samedi de chaque mois, venez ren...              2\n",
              "4798  4798  Les co√ªts li√©s √† la journalisation n'√©tant pas...              5\n",
              "4799  4799  Sur le sable, la mer haletait de toute la resp...              5\n",
              "\n",
              "[4800 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5036815-4855-4252-affa-c700826e2796\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>oe_difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les co√ªts kilom√©triques r√©els peuvent diverger...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en fran√ßais est sur le site ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les √©coles de commerce, dans les couloirs...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>4795</td>\n",
              "      <td>C'est pourquoi, il d√©cida de remplacer les hab...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>4796</td>\n",
              "      <td>Il avait une de ces p√¢leurs splendides qui don...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>4797</td>\n",
              "      <td>Et le premier samedi de chaque mois, venez ren...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>4798</td>\n",
              "      <td>Les co√ªts li√©s √† la journalisation n'√©tant pas...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>4799</td>\n",
              "      <td>Sur le sable, la mer haletait de toute la resp...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5036815-4855-4252-affa-c700826e2796')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5036815-4855-4252-affa-c700826e2796 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5036815-4855-4252-affa-c700826e2796');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lenghts of messages\n",
        "df_one['oe_difficulty'] = [0 if x == 'A1'\n",
        "                   else 2 if x =='A2'\n",
        "                   else 1 if x== 'B1'\n",
        "                   else 3 if x == 'B2'\n",
        "                   else 4 if x == 'C1'\n",
        "                   else 5\n",
        "                   for x in df.difficulty]\n",
        "df.drop(labels='difficulty', axis=1)\n",
        "\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df_one['sentence'], df_one['oe_difficulty'],\n",
        "                                                                    random_state=2018,     \n",
        "                                                                    test_size=0.1, \n",
        "                                                                    stratify=df_one['oe_difficulty']) \n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.1, \n",
        "                                                                stratify=temp_labels)"
      ],
      "metadata": {
        "id": "FLiKL6NEkYGD"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)\n",
        "\n",
        "#The longest sequence message is 265\n",
        "max(seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "zDH3a2vGlSMm",
        "outputId": "d719b0f3-1caa-4c69-aaa1-05caa4ee1e0b"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "265"
            ]
          },
          "metadata": {},
          "execution_count": 165
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization \n",
        "#BERT uses Wordpiece tokenization: \n",
        "#The vocabulary is initialized with all the individual \n",
        "#characters in the language, and then the most frequent/likely combinations \n",
        "#of the existing words in the vocabulary are iteratively added.\n",
        "\n",
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = 150,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True)\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = 150,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True)\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 150,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHz-Bcevloc7",
        "outputId": "7cd06035-14e7-4f0c-b122-716404a2896e"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## convert lists to tensors\n",
        "\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "ZJfqwDq5mi8F"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 1000\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "h585hUQWxllD"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "r2B5Y6TBxsEi"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        \n",
        "        self.bert = bert \n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "        # relu activation function\n",
        "        self.relu =  nn.ReLU()\n",
        "\n",
        "        #Longest sequence = 265\n",
        "        # dense layer 1\n",
        "        self.fc1 = nn.Linear(768,265)\n",
        "      \n",
        "        #longest sequence 265 and 6 classes\n",
        "        # dense layer 2 (Output layer)\n",
        "        \n",
        "        self.fc2 = nn.Linear(265,6)\n",
        "\n",
        "        #softmax activation function\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "        \n",
        "        #pass the inputs to the model  \n",
        "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "        x = self.fc1(cls_hs)\n",
        "\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # output layer\n",
        "        x = self.fc2(x)\n",
        "      \n",
        "        # apply softmax activation\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "u_QzrWA4xvY1"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "cUVhhENvx0XS"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),lr = 1e-5) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UYTGvLtx3Fc",
        "outputId": "d6da036f-2401-4946-eab7-b6db1548c328"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes= np.unique(train_labels), y= train_labels)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqepu_WRx6BR",
        "outputId": "8bc9b3c7-ffd9-4120-8698-7ae344f960da"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [0.98360656 1.00699301 1.00558659 1.00981767 1.00278552 0.99173554]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# push to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "HiPZ8E2mCBEa"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## FINE TUNE\n",
        "\n",
        "# function to train the model\n",
        "def train():\n",
        "    \n",
        "    model.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "  \n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "        \n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "        \n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        " \n",
        "        sent_id, mask, labels = batch\n",
        "        \n",
        "        # clear previously calculated gradients \n",
        "        model.zero_grad()        \n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "      # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "HljvGTgXCHGG"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "    \n",
        "    print(\"\\nEvaluating...\")\n",
        "  \n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "    \n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "        \n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            \n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            # model predictions\n",
        "            preds = model(sent_id, mask)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "\n",
        "            total_preds.append(preds)\n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "fO__50MdCK77"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6LkXbVoCW9Q",
        "outputId": "d1e65c8a-449a-49e0-f750-66dcf9c757bd"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.745\n",
            "Validation Loss: 1.737\n",
            "\n",
            " Epoch 2 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.741\n",
            "Validation Loss: 1.736\n",
            "\n",
            " Epoch 3 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.739\n",
            "Validation Loss: 1.735\n",
            "\n",
            " Epoch 4 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.740\n",
            "Validation Loss: 1.733\n",
            "\n",
            " Epoch 5 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.737\n",
            "Validation Loss: 1.732\n",
            "\n",
            " Epoch 6 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.737\n",
            "Validation Loss: 1.730\n",
            "\n",
            " Epoch 7 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.732\n",
            "Validation Loss: 1.729\n",
            "\n",
            " Epoch 8 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.732\n",
            "Validation Loss: 1.727\n",
            "\n",
            " Epoch 9 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.727\n",
            "Validation Loss: 1.726\n",
            "\n",
            " Epoch 10 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.731\n",
            "Validation Loss: 1.724\n",
            "\n",
            " Epoch 11 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.729\n",
            "Validation Loss: 1.722\n",
            "\n",
            " Epoch 12 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.729\n",
            "Validation Loss: 1.721\n",
            "\n",
            " Epoch 13 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.727\n",
            "Validation Loss: 1.719\n",
            "\n",
            " Epoch 14 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.724\n",
            "Validation Loss: 1.718\n",
            "\n",
            " Epoch 15 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.722\n",
            "Validation Loss: 1.716\n",
            "\n",
            " Epoch 16 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.724\n",
            "Validation Loss: 1.714\n",
            "\n",
            " Epoch 17 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.720\n",
            "Validation Loss: 1.713\n",
            "\n",
            " Epoch 18 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.719\n",
            "Validation Loss: 1.711\n",
            "\n",
            " Epoch 19 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.719\n",
            "Validation Loss: 1.710\n",
            "\n",
            " Epoch 20 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.711\n",
            "Validation Loss: 1.708\n",
            "\n",
            " Epoch 21 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.718\n",
            "Validation Loss: 1.707\n",
            "\n",
            " Epoch 22 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.715\n",
            "Validation Loss: 1.705\n",
            "\n",
            " Epoch 23 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.713\n",
            "Validation Loss: 1.704\n",
            "\n",
            " Epoch 24 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.707\n",
            "Validation Loss: 1.703\n",
            "\n",
            " Epoch 25 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.712\n",
            "Validation Loss: 1.701\n",
            "\n",
            " Epoch 26 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.712\n",
            "Validation Loss: 1.700\n",
            "\n",
            " Epoch 27 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.707\n",
            "Validation Loss: 1.699\n",
            "\n",
            " Epoch 28 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.706\n",
            "Validation Loss: 1.697\n",
            "\n",
            " Epoch 29 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.708\n",
            "Validation Loss: 1.696\n",
            "\n",
            " Epoch 30 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.704\n",
            "Validation Loss: 1.695\n",
            "\n",
            " Epoch 31 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.702\n",
            "Validation Loss: 1.694\n",
            "\n",
            " Epoch 32 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.704\n",
            "Validation Loss: 1.692\n",
            "\n",
            " Epoch 33 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.698\n",
            "Validation Loss: 1.691\n",
            "\n",
            " Epoch 34 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.704\n",
            "Validation Loss: 1.689\n",
            "\n",
            " Epoch 35 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.696\n",
            "Validation Loss: 1.688\n",
            "\n",
            " Epoch 36 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.693\n",
            "Validation Loss: 1.686\n",
            "\n",
            " Epoch 37 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.695\n",
            "Validation Loss: 1.685\n",
            "\n",
            " Epoch 38 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.697\n",
            "Validation Loss: 1.684\n",
            "\n",
            " Epoch 39 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.699\n",
            "Validation Loss: 1.683\n",
            "\n",
            " Epoch 40 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.693\n",
            "Validation Loss: 1.681\n",
            "\n",
            " Epoch 41 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.693\n",
            "Validation Loss: 1.680\n",
            "\n",
            " Epoch 42 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.692\n",
            "Validation Loss: 1.679\n",
            "\n",
            " Epoch 43 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.692\n",
            "Validation Loss: 1.678\n",
            "\n",
            " Epoch 44 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.691\n",
            "Validation Loss: 1.676\n",
            "\n",
            " Epoch 45 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.691\n",
            "Validation Loss: 1.675\n",
            "\n",
            " Epoch 46 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.688\n",
            "Validation Loss: 1.674\n",
            "\n",
            " Epoch 47 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.688\n",
            "Validation Loss: 1.673\n",
            "\n",
            " Epoch 48 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.688\n",
            "Validation Loss: 1.672\n",
            "\n",
            " Epoch 49 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.690\n",
            "Validation Loss: 1.671\n",
            "\n",
            " Epoch 50 / 50\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.685\n",
            "Validation Loss: 1.670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "6BxWEFVXDtmG",
        "outputId": "3ebb0f3e-ce9e-42b7-b428-55a3049b0c9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## HERE WE MAKING PREDICTIONS\n",
        "\n",
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "-MjUxPoSDxfi"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "id": "EiDm1VFhD1Se",
        "outputId": "58e65418-617d-40f4-d816-ec9916c2d54b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.88      0.74         8\n",
            "           1       1.00      0.12      0.22         8\n",
            "           2       0.00      0.00      0.00         8\n",
            "           3       0.20      0.12      0.15         8\n",
            "           4       0.26      0.75      0.39         8\n",
            "           5       0.40      0.25      0.31         8\n",
            "\n",
            "    accuracy                           0.35        48\n",
            "   macro avg       0.42      0.35      0.30        48\n",
            "weighted avg       0.42      0.35      0.30        48\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_one"
      ],
      "metadata": {
        "id": "dVn8avA3RwPA",
        "outputId": "e0f034dc-0a5b-4b72-a87f-4cb7406bcb9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                           sentence  oe_difficulty\n",
              "0        0  Les co√ªts kilom√©triques r√©els peuvent diverger...              4\n",
              "1        1  Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...              0\n",
              "2        2  Le test de niveau en fran√ßais est sur le site ...              0\n",
              "3        3           Est-ce que ton mari est aussi de Boston?              0\n",
              "4        4  Dans les √©coles de commerce, dans les couloirs...              1\n",
              "...    ...                                                ...            ...\n",
              "4795  4795  C'est pourquoi, il d√©cida de remplacer les hab...              3\n",
              "4796  4796  Il avait une de ces p√¢leurs splendides qui don...              4\n",
              "4797  4797  Et le premier samedi de chaque mois, venez ren...              2\n",
              "4798  4798  Les co√ªts li√©s √† la journalisation n'√©tant pas...              5\n",
              "4799  4799  Sur le sable, la mer haletait de toute la resp...              5\n",
              "\n",
              "[4800 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90e43387-059c-4483-91fe-333dce5c2c5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>oe_difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les co√ªts kilom√©triques r√©els peuvent diverger...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur pr√©f√©r√©e mais je n'a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en fran√ßais est sur le site ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les √©coles de commerce, dans les couloirs...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>4795</td>\n",
              "      <td>C'est pourquoi, il d√©cida de remplacer les hab...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>4796</td>\n",
              "      <td>Il avait une de ces p√¢leurs splendides qui don...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>4797</td>\n",
              "      <td>Et le premier samedi de chaque mois, venez ren...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>4798</td>\n",
              "      <td>Les co√ªts li√©s √† la journalisation n'√©tant pas...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>4799</td>\n",
              "      <td>Sur le sable, la mer haletait de toute la resp...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90e43387-059c-4483-91fe-333dce5c2c5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90e43387-059c-4483-91fe-333dce5c2c5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90e43387-059c-4483-91fe-333dce5c2c5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Batch 32\n",
        "#epoch 10\n",
        "#Accuracy 0.26\n",
        "\n",
        "#Batch 1000\n",
        "#epoch 1000\n",
        "#Accuracy:\n",
        "# 0.32\n",
        "\n",
        "#Batch 1000\n",
        "#epoch100\n",
        "#tokenization 50\n",
        "#0.33 \n",
        "\n",
        "#Batch 10000\n",
        "#epoch 50\n",
        "#tokenization 100\n",
        "#0.35 \n",
        "\n",
        "#Batch 1000\n",
        "#epoch 100\n",
        "#tokenization 150\n"
      ],
      "metadata": {
        "id": "3gs9cNeNGj6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test also so this \n",
        "#LR_cv = LogisticRegressionCV(solver='sag', cv=10, max_iter=100, random_state = 0, warm_start= bool,)"
      ],
      "metadata": {
        "id": "sktG_K5RloBT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Project_guidelines_2022.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}