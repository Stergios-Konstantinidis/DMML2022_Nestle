{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZKqCFFbNZ04"
      },
      "source": [
        "# Data Mining and Machine Learning - Project\n",
        "\n",
        "## Detecting Difficulty Level of French Texts\n",
        "\n",
        "### Step by step guidelines\n",
        "\n",
        "The following are a set of step by step guidelines to help you get started with your project for the Data Mining and Machine Learning class. \n",
        "To test what you learned in the class, we will hold a competition. You will create a classifier that predicts how the level of some text in French (A1,..., C2). The team with the highest rank will get some goodies in the last class (some souvenirs from tech companies: Amazon, LinkedIn, etc).\n",
        "\n",
        "**2 people per team**\n",
        "\n",
        "Choose a team here:\n",
        "https://moodle.unil.ch/mod/choicegroup/view.php?id=1305831\n",
        "\n",
        "\n",
        "#### 1. ðŸ“‚ Create a public GitHub repository for your team using this naming convention `DMML2022_[your_team_name]` with the following structure:\n",
        "- data (folder) \n",
        "- code (folder) \n",
        "- documentation (folder)\n",
        "- a readme file (.md): *mention team name, participants, brief description of the project, approach, summary of results table and link to the explainatory video (see below).*\n",
        "\n",
        "All team members should contribute to the GitHub repository.\n",
        "\n",
        "#### 2. ðŸ‡° Join the competititon on Kaggle using the invitation link we sent on Slack.\n",
        "\n",
        "Under the Team tab, save your team name (`UNIL_your_team_name`) and make sure your team members join in as well. You can merge your user account with your teammates in order to create a team.\n",
        "\n",
        "#### 3. ðŸ““ Read the data into your colab notebook. There should be one code notebook per team, but all team members can participate and contribute code. \n",
        "\n",
        "You can use either direct the Kaggle API and your Kaggle credentials (as explained below and **entirely optional**), or dowload the data form Kaggle and upload it onto your team's GitHub repository under the data subfolder.\n",
        "\n",
        "#### 4. ðŸ’Ž Train your models and upload the code under your team's GitHub repo. Set the `random_state=0`.\n",
        "- baseline\n",
        "- logistic regression with TFidf vectoriser (simple, no data cleaning)\n",
        "- KNN & hyperparameter optimisation (simple, no data cleaning)\n",
        "- Decision Tree classifier & hyperparameter optimisation (simple, no data cleaning)\n",
        "- Random Forests classifier (simple, no data cleaning)\n",
        "- another technique or combination of techniques of your choice\n",
        "\n",
        "BE CREATIVE! You can use whatever method you want, in order to climb the leaderboard. The only rule is that it must be your own work. Given that, you can use all the online resources you want. \n",
        "\n",
        "#### 5. ðŸŽ¥ Create a YouTube video (10-15 minutes) of your solution and embed it in your notebook. Explain the algorithms used and the evaluation of your solutions. *Select* projects will also be presented live by the group during the last class.\n",
        "\n",
        "\n",
        "### Submission details (one per team)\n",
        "\n",
        "1. Download a ZIPped file of your team's repository and submit it in Moodle here. IMPORTANT: in the comment of the submission, insert a link to the repository on Github.\n",
        "https://moodle.unil.ch/mod/assign/view.php?id=1305833\n",
        "\n",
        "\n",
        "\n",
        "### Grading (one per team)\n",
        "- 20% Kaggle Rank\n",
        "- 50% code quality (using classes, splitting into proper files, documentation, etc)\n",
        "- 15% github quality (include link to video, table with progress over time, organization of code, images, etc)\n",
        "- 15% video quality (good sound, good slides, interesting presentation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-14CAdOoinM"
      },
      "source": [
        "## Some further details for points 3 and 4 above.\n",
        "\n",
        "### 3. Read data into your notebook with the Kaggle API (optional but useful). \n",
        "\n",
        "You can also download the data from Kaggle and put it in your team's repo the data folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKG1TCddRYTB"
      },
      "source": [
        "### IMPORTANT\n",
        "Log into your Kaggle account, go to Account > API > Create new API token. You will obtain a kaggle.json file. Save it in your Google Drive (not in a folder, in your general drive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ei1RgilX3ws6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be276003-80d1-4ad3-9906-a0ebac38f181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1 MB 7.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "#do you need to download the data again?\n",
        "#test\n",
        "!pip install --upgrade pip\n",
        "!pip install sklearn\n",
        "download = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDI60LXKTPzf"
      },
      "outputs": [],
      "source": [
        "if download == True:\n",
        "    !kaggle competitions download -c detecting-french-texts-difficulty-level-2022\n",
        "    !pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywx7z7SN3ws6"
      },
      "outputs": [],
      "source": [
        "if download == True:\n",
        "    !unzip \"detecting-french-texts-difficulty-level-2022.zip\" -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daqvj7feTx60",
        "outputId": "0e176ab3-fb5c-4f2e-89ce-872432af95b2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[256], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/training_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "# read in your training data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "df = pd.read_csv('data/training_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxRSnk5bhTp8"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kpfbtndj0jL"
      },
      "source": [
        "Have a look at the data on which to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G75Q1gRj49l"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.read_csv('data/unlabelled_test_data.csv')\n",
        "df_pred.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a37hWJ_ckBlk"
      },
      "source": [
        "And this is the format for your submissions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk9H2dLHkFBa"
      },
      "outputs": [],
      "source": [
        "df_example_submission = pd.read_csv('data/sample_submission.csv')\n",
        "df_example_submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfTgL1erjqQ6"
      },
      "source": [
        "### 4. Train your models\n",
        "\n",
        "Set your X and y variables. \n",
        "Set the `random_state=0`\n",
        "Split the data into a train and test set using the following parameters `train_test_split(X, y, test_size=0.2, random_state=0)`.\n",
        "\n",
        "#### 4.1.Baseline\n",
        "What is the baseline for this classification problem?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4O_pYiHpiRd"
      },
      "outputs": [],
      "source": [
        "np.random.seed = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDdFr4xsk5Qf"
      },
      "outputs": [],
      "source": [
        "# your code here (you can use as many lines of code as you like)\n",
        "X = df['difficulty']\n",
        "y = df['sentence']\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "D1LAbIVGbPaw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlvbPYa0k78l"
      },
      "source": [
        "#### 4.2. Logistic Regression (without data cleaning)\n",
        "\n",
        "Train a simple logistic regression model using a Tfidf vectoriser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEe3-QNlow4H"
      },
      "outputs": [],
      "source": [
        "# your cofrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words=\"french\")\n",
        "features = tfidf.fit_transform(texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ-qO8C5oyov"
      },
      "source": [
        "Calculate accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PViIQdnDpASy"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D3_dp3apcmr"
      },
      "source": [
        "Have a look at the confusion matrix and identify a few examples of sentences that are not well classified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSyKq3h_qZmX"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TTEiuXasNFg"
      },
      "source": [
        "Generate your first predictions on the `unlabelled_test_data.csv`. make sure your predictions match the format of the `unlabelled_test_data.csv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXG_yIG_pQ8t"
      },
      "source": [
        "#### 4.3. KNN (without data cleaning)\n",
        "\n",
        "Train a KNN classification model using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPRjD1rSqKKZ"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6rH2Hx0qtB2"
      },
      "source": [
        "Try to improve it by tuning the hyper parameters (`n_neighbors`,   `p`, `weights`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRy18Ce_qxPc"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFNH1WgNqc62"
      },
      "source": [
        "#### 4.4. Decision Tree Classifier (without data cleaning)\n",
        "\n",
        "Train a Decison Tree classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4PByPdGq0FV"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQHjvOp7q11L"
      },
      "source": [
        "Try to improve it by tuning the hyper parameters (`max_depth`, the depth of the decision tree)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Fzl5BUq8JN"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M52Ys3hcq7ku"
      },
      "source": [
        "#### 4.5. Random Forest Classifier (without data cleaning)\n",
        "\n",
        "Try a Random Forest Classifier, using a Tfidf vectoriser. Show the accuracy, precision, recall and F1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sssF4NIGrNLa"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-8_3MK1rpZr"
      },
      "source": [
        "#### 4.6. Any other technique, including data cleaning if necessary\n",
        "\n",
        "Try to improve accuracy by training a better model using the techniques seen in class, or combinations of them.\n",
        "\n",
        "As usual, show the accuracy, precision, recall and f1 score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX5AjvvKr_nW"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82FvnJycsBFf"
      },
      "source": [
        "#### 4.7. Show a summary of your results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "Ygw6N1rSbPa6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "QVB9adKXbPa7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "1n6NyIKPbPa7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "xYcc_vRgbPa7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}